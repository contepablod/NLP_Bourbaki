{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Colegio Bourbaki](./Images/Bourbaki.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesamiento de Lenguaje Natural"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contexto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de este notebook es hacer una demostración de la creación de chatbots estilo ChatGPT con conocimiento de datos específicos.\n",
    "\n",
    "En primer lugar, enseñaremos cómo conectar con el API de OpenAI para utilizar GPT-3.5 Turbo, el modelo que alimenta a la versión abierta de ChatGPT, desde código.\n",
    "\n",
    "Después, veremos cómo podemos introducir material a la base de conocimiento del chatbot, para así obtener respuestas más personalizadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP Chatbots\n",
    "#!pip install openai langchain duckdb unstructured chromadb tiktoken\n",
    "import openai\n",
    "from langchain.document_loaders.unstructured import UnstructuredFileLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import VectorDBQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "#Utils\n",
    "import os\n",
    "from dotenv import load_dotenv #!pip install python-dotenv\n",
    "from pdfminer.high_level import extract_text #!pip install pdfminer.six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conectamos con el API GPT-3.5 por medio de una llave privada a cada usuario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv() # This method loads the variables from .env into the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#api_key = os.environ['CHATGPT_API_KEY']\n",
    "api_key = os.getenv(\"CHATGPT_API_KEY\") # This method loads the variables from .env into the environment with dotenv\n",
    "if api_key is None:\n",
    "    raise ValueError(\"API key not found. Please set the CHATGPT_API_KEY environment variable.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI(\n",
    "    api_key=api_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez hecha la conexión con GPT-3.5 podemos aprovechar las capacidades conversacionales de ChatGPT. \n",
    "\n",
    "Desde este punto ya es posible integrar asistentes inteligentes a aplicaciones y sistemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"¡Hola! ¿Por qué el cielo es azul?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    #model=\"gpt-4\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Hola! El cielo se ve azul debido a un fenómeno llamado dispersión de la luz. La luz del sol está compuesta por diferentes colores, cada uno con una longitud de onda diferente. Cuando la luz del sol atraviesa la atmósfera de la Tierra, las moléculas de aire dispersan los colores de luz de manera diferente. Los colores más cortos, como el azul y el violeta, se dispersan más que los colores más largos, como el rojo y el naranja. Esto significa que vemos principalmente el color azul dispersado en el cielo durante el día, lo que nos da esa apariencia azul. Por la noche, cuando el sol no está presente, el cielo se ve oscuro porque la luz del sol ya no la ilumina.\n"
     ]
    }
   ],
   "source": [
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos lograr mejores respuestas del modelo si modificamos el atributo **system**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sistema = \"Eres un asistente de poetas, habilidoso en explicar conceptos complejos de programación creativamente.\"\n",
    "usuario = \"Compón un poema que explique el concepto de recursión en programación.\"\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": sistema},\n",
    "    {\"role\": \"user\", \"content\": usuario}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En el vasto lenguaje de código enredado,\n",
      "donde la lógica y la creatividad se han encontrado,\n",
      "existe un concepto, brillante y profundo,\n",
      "que se llama recursión, un poderoso mundo.\n",
      "\n",
      "Imagina un bucle, tan intrincado,\n",
      "que no es lineal, sino un tanto enredado,\n",
      "una función que se llama a sí misma,\n",
      "volviendo al principio sin ninguna envidia.\n",
      "\n",
      "Como un laberinto de caminos sin fin,\n",
      "la recursión sigue patrones, sin limitación,\n",
      "dividiendo problemas en tareas más pequeñas,\n",
      "resolviendo cada una con maestría y destreza.\n",
      "\n",
      "En cada iteración, se acerca a la solución,\n",
      "rompiendo problemas con gran resolución,\n",
      "hasta que se cumpla una condición de salida,\n",
      "y se desenmarañen los nudos, sin prisa.\n",
      "\n",
      "Es como un espejo que se refleja a sí mismo,\n",
      "creando copias de sí, sin pensar en sí mismo,\n",
      "un eco infinito de instrucciones recursivas,\n",
      "hasta que el problema original se desvanece.\n",
      "\n",
      "Aunque puede ser difícil de dominar,\n",
      "la recursión es un arte, un modo de pensar,\n",
      "un enfoque poderoso y elegante,\n",
      "que a problemas complejos da un giro fascinante.\n",
      "\n",
      "Así que, oh programador, no temas su poder,\n",
      "abrázalo con fuerza, deja que florezca tu ser,\n",
      "y con recursión, conquista el código que creas,\n",
      "dándole vida y forma a tus ideas.\n"
     ]
    }
   ],
   "source": [
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de un asistente especializado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A su vez, podemos aprovechar aún más las capacidades de loss LLM haciendo una especie de fine-tuning. La idea consiste en alimentar al modelos con documentos propios para así lograr respuestas informadas sobre ellos.\n",
    "\n",
    "Esto es posible en GPT-3.5 a través de los encajes y la generación de una base de datos vectorizada.\n",
    "\n",
    "Primero, extraemos texto desde archivos pdfs...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... y extramos el texto de un pdf para después guardarlo en .txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractor_texto(ruta):\n",
    "    # Assume extract_text is a function defined elsewhere to extract text from the given path\n",
    "    txt = extract_text(ruta)\n",
    "    \n",
    "    # Clean and format the text\n",
    "    replacements = {\n",
    "        '\\n\\n\\x0c': ' ',  # Remove specific pattern\n",
    "        '...': ' ',       # Replace ellipses with space\n",
    "        '\\n': ' ',        # Replace newline characters with space\n",
    "        '  ': ' ',        # Replace double spaces with single space\n",
    "        \"\\f\": ' ',        # Remove form feed characters\n",
    "        \"-\": ' '          # Replace hyphens with space\n",
    "    }\n",
    "    \n",
    "    # Apply replacements\n",
    "    for old, new in replacements.items():\n",
    "        txt = txt.replace(old, new)\n",
    "    \n",
    "    # Split into paragraphs and filter based on conditions\n",
    "    paragraphs = txt.split('\\n\\n')\n",
    "    paragraphs = [paragraph.strip() for paragraph in paragraphs if len(paragraph.strip()) > 30]\n",
    "    \n",
    "    # Join the cleaned paragraphs\n",
    "    cleaned_text = '\\n'.join(paragraphs)\n",
    "    \n",
    "    # Write the cleaned text to a file, appending '.txt' to the original path and using utf-16 encoding\n",
    "    with open(ruta + '.txt', \"w\", encoding=\"utf-16\") as archivo:\n",
    "        archivo.write(cleaned_text)\n",
    "    \n",
    "    # Optionally, return the cleaned text if needed\n",
    "    return cleaned_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta = './Data/Feynman1982_Article_SimulatingPhysicsWithComputers.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper = extractor_texto(ruta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Data/output.txt\", \"w\") as text_file:\n",
    "    print(paper, file=text_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1460, which is longer than the specified 1000\n",
      "Created a chunk of size 1493, which is longer than the specified 1000\n",
      "Created a chunk of size 1480, which is longer than the specified 1000\n",
      "Created a chunk of size 1385, which is longer than the specified 1000\n",
      "Created a chunk of size 1425, which is longer than the specified 1000\n",
      "Created a chunk of size 1405, which is longer than the specified 1000\n",
      "Created a chunk of size 1348, which is longer than the specified 1000\n",
      "Created a chunk of size 1484, which is longer than the specified 1000\n",
      "Created a chunk of size 1354, which is longer than the specified 1000\n",
      "Created a chunk of size 1467, which is longer than the specified 1000\n",
      "Created a chunk of size 1318, which is longer than the specified 1000\n",
      "Created a chunk of size 1437, which is longer than the specified 1000\n",
      "Created a chunk of size 1490, which is longer than the specified 1000\n",
      "Created a chunk of size 1315, which is longer than the specified 1000\n",
      "Created a chunk of size 1339, which is longer than the specified 1000\n",
      "Created a chunk of size 1393, which is longer than the specified 1000\n",
      "Created a chunk of size 1452, which is longer than the specified 1000\n",
      "Created a chunk of size 1447, which is longer than the specified 1000\n",
      "Created a chunk of size 1496, which is longer than the specified 1000\n",
      "Created a chunk of size 1408, which is longer than the specified 1000\n",
      "Created a chunk of size 1333, which is longer than the specified 1000\n",
      "Created a chunk of size 1484, which is longer than the specified 1000\n",
      "Created a chunk of size 1423, which is longer than the specified 1000\n",
      "Created a chunk of size 1385, which is longer than the specified 1000\n",
      "Created a chunk of size 1482, which is longer than the specified 1000\n",
      "Created a chunk of size 1485, which is longer than the specified 1000\n",
      "Created a chunk of size 1473, which is longer than the specified 1000\n",
      "Created a chunk of size 1476, which is longer than the specified 1000\n",
      "Created a chunk of size 1470, which is longer than the specified 1000\n",
      "Created a chunk of size 1477, which is longer than the specified 1000\n",
      "Created a chunk of size 1424, which is longer than the specified 1000\n",
      "Created a chunk of size 1454, which is longer than the specified 1000\n",
      "Created a chunk of size 1454, which is longer than the specified 1000\n",
      "Created a chunk of size 1414, which is longer than the specified 1000\n",
      "Created a chunk of size 1332, which is longer than the specified 1000\n",
      "Created a chunk of size 1355, which is longer than the specified 1000\n",
      "Created a chunk of size 1435, which is longer than the specified 1000\n",
      "Created a chunk of size 1380, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "loader = UnstructuredFileLoader('./Data/output.txt')\n",
    "documents = loader.load()\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "embeddings = OpenAIEmbeddings(openai_api_key = api_key)\n",
    "\n",
    "db = Chroma.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En seguida, cargamos el documento a la base de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = VectorDBQA.from_chain_type(llm=ChatOpenAI(openai_api_key=api_key), chain_type=\"stuff\", vectorstore=db, k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este modelo ahora se puede utilizar como un ChatGPT con conocimiento especializado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The document is about Richard P. Feynman's keynote speech on the topic of simulating physics with computers. Feynman discusses the inspiration for his interest in the subject and the potential for learning about both computers and physics through simulation.\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What the document is about?\"\n",
    "qa.run(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y es posible obtener respuestas muy específicas y personalizadas sobre nuestros documentos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Photons can be polarized through a process called polarization. Polarization refers to the orientation of the electric field vector of a light wave. When light is unpolarized, the electric field vector can vibrate in any direction perpendicular to the direction of propagation. However, when light passes through certain materials or undergoes certain interactions, the electric field vector becomes restricted to a specific orientation, resulting in polarized light. This can be achieved through various methods, such as using polarizers or passing light through certain crystals.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"How photons are polarized?\"\n",
    "qa.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In traditional probability theory, probabilities are always non-negative values between 0 and 1. However, in certain contexts, such as quantum mechanics, the concept of negative probabilities has been explored.\\n\\nNegative probabilities can be thought of as a mathematical tool to describe situations where the probability of an event occurring is less than zero. This may seem counterintuitive, as probabilities are typically associated with the likelihood of something happening. However, in quantum mechanics, negative probabilities can arise when dealing with certain quantum states or processes.\\n\\nOne interpretation of negative probabilities in quantum mechanics is that they represent a type of \"anti-probability\" or \"anti-chance.\" These negative probabilities can be used to describe phenomena such as quantum superposition, where a particle can exist in multiple states simultaneously. In this case, the negative probabilities can be seen as indicating the interference or cancellation of different possibilities.\\n\\nIt is important to note that negative probabilities do not have the same interpretation as positive probabilities. They are not directly associated with the likelihood of an event occurring in the same way as traditional probabilities. Instead, negative probabilities are a mathematical tool that can be used in certain contexts, particularly in quantum mechanics, to describe and analyze complex phenomena.\\n\\nIt is worth mentioning that the concept of negative probabilities is still a topic of ongoing research and debate in the field of quantum mechanics. While they may seem unconventional, they have proven to be useful in certain theoretical frameworks and have led to new insights and understanding of quantum phenomena.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Expand the concept of negative probabilities\"\n",
    "qa.run(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conexión con la API de OpenAI:**\n",
    "\n",
    "1) ¿Qué información necesitas para autenticarte y realizar peticiones al API de OpenAI?\n",
    "2) ¿Cuál es el propósito de utilizar una clave API en la conexión con OpenAI y cómo se debe proteger?\n",
    "3) ¿Qué diferencias hay entre los distintos modelos de OpenAI y cómo elegirías uno para tu aplicación específica?\n",
    "\n",
    "**Uso de GPT-3.5 Turbo:**\n",
    "\n",
    "4) ¿Qué ventajas ofrece GPT-3.5 Turbo para la creación de chatbots comparado con versiones anteriores?\n",
    "5) ¿Cómo se formulan las peticiones al modelo GPT-3.5 Turbo para generar respuestas coherentes y relevantes?\n",
    "6) ¿Qué limitaciones tiene el modelo GPT-3.5 Turbo y cómo puedes mitigarlas?\n",
    "\n",
    "**Introducción de Material a la Base de Conocimiento:**\n",
    "\n",
    "7) ¿Cómo puedes personalizar las respuestas de GPT-3.5 Turbo utilizando información específica?\n",
    "8) ¿Cuál es la importancia de la relevancia y precisión del material que se introduce en la base de conocimientos del bot?\n",
    "9) ¿Qué estrategias se pueden utilizar para mantener actualizada la base de conocimientos del chatbot?\n",
    "\n",
    "**Personalización y Respuestas del Chatbot:**\n",
    "\n",
    "10) ¿De qué manera se puede ajustar el tono o el estilo de las respuestas que genera GPT-3.5 Turbo?\n",
    "11) ¿Cómo afecta el contexto proporcionado a las respuestas generadas por el chatbot?\n",
    "    Describe un método para evaluar la precisión y utilidad de las respuestas del chatbot.\n",
    "\n",
    "**Problemas Éticos y de Privacidad:**\n",
    "\n",
    "12) ¿Cuáles son las consideraciones éticas al utilizar modelos de lenguaje generativos como GPT-3.5 Turbo en un chatbot?\n",
    "13) ¿Cómo debería manejar un chatbot las solicitudes de datos personales o sensibles de los usuarios?\n",
    "14) ¿Qué medidas se pueden tomar para garantizar la privacidad y la seguridad de los usuarios al interactuar con un chatbot?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Lenguaje Matemático](./Images/Matematicas.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Contacto](./Images/Contacto.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
