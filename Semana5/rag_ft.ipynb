{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bf9e6d1",
   "metadata": {},
   "source": [
    "![Colegio Bourbaki](./Images/Bourbaki.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb70ffd6",
   "metadata": {},
   "source": [
    "## Procesamiento de Lenguaje Natural"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda9a929",
   "metadata": {},
   "source": [
    "En este notebook haremos lo siguiente:\n",
    "\n",
    "1. **Explicaremos** la diferencia entre:   \n",
    "- Generación aumentada por recuperación (**RAG**)   \n",
    "- **Ajuste fino** de un modelo de lenguaje\n",
    "- Uso de **ambos juntos** \n",
    "\n",
    "2. **Implementaremos un pequeño proceso RAG**:   \n",
    "- Usaremos un transformador de oraciones para incrustar documentos  \n",
    "- Almacenaremos las incrustaciones en un índice vectorial  \n",
    "- Recuperaremos pasajes relevantes  \n",
    "- Usaremos un pequeño modelo de chat de pesos abiertos para responder preguntas de ese contexto \n",
    "\n",
    "3. **Ajustar un pequeño modelo de pesos abiertos** en un pequeño conjunto de datos de preguntas y respuestas   \n",
    "- Utilizar LoRA / QLoRA para ajustarlo a una GPU de ~4 GB   \n",
    "- Comparar las respuestas **antes y después** del ajuste. Se trata de una GPU como la **NVIDIA GeForce GTX 1650 Ti 4 GB**, por lo que haremos lo siguiente: - Utilizar un modelo pequeño: `TinyLlama/TinyLlama-1.1B-Chat-v1.0`. \n",
    "- Cargarlo en **4 bits** siempre que sea posible. \n",
    "- Mantener tamaños de lote pequeños.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f44efd8",
   "metadata": {},
   "source": [
    "## RAG frente al ajuste fino (conceptual)\n",
    "\n",
    "### ¿Qué es RAG (generación aumentada por recuperación)?\n",
    "\n",
    "Los LLM tienen un **conocimiento limitado**: solo saben lo que vieron durante el entrenamiento previo.  \n",
    "RAG añade un **almacén de conocimiento externo** (por ejemplo, una base de datos vectorial):\n",
    "\n",
    "1. Se **incrustan** los documentos (artículos, documentos, tickets) en vectores.\n",
    "2. En el momento de la consulta, se:\n",
    "   - Incrusta la pregunta del usuario.\n",
    "   - Recupera los **documentos más similares**.\n",
    "   - Pasa la *pregunta + el contexto recuperado* al LLM.\n",
    "3. El modelo responde *utilizando ese contexto*, sin cambiar sus pesos.\n",
    "\n",
    "**Ventajas:**\n",
    "- Ideal para **datos nuevos y que cambian con frecuencia** (como las noticias diarias).\n",
    "- No requiere un entrenamiento pesado, solo incrustación + recuperación.\n",
    "- Seguro: no sobrescribe el modelo.\n",
    "\n",
    "**Desventajas:**\n",
    "- La calidad de la respuesta depende de la **calidad de la recuperación** y del tamaño de la solicitud.\n",
    "- Limitado por la **ventana de contexto**: solo se puede pasar una cantidad limitada de texto.\n",
    "\n",
    "---\n",
    "\n",
    "### ¿Qué es el ajuste fino?\n",
    "\n",
    "El ajuste fino significa **continuar entrenando** un LLM preentrenado en una **tarea o dominio específico**:\n",
    "\n",
    "- Ejemplo: miles de pares de preguntas y respuestas sobre la nube, Kubernetes, fintech, etc.\n",
    "- El modelo **actualiza sus pesos** para interiorizar este dominio.\n",
    "\n",
    "**Ventajas:**\n",
    "- El modelo mejora de forma nativa en ese dominio o estilo.\n",
    "- No es necesario proporcionar siempre un contexto largo: «sabe» más en sus pesos.\n",
    "\n",
    "**Desventajas:**\n",
    "- **Es costoso** (tiempo de GPU, canalización de entrenamiento).\n",
    "- Necesita **datos buenos y seleccionados**.\n",
    "- El modelo sigue teniendo un límite de conocimiento fijo (no «verá» nuevos artículos a menos que se vuelva a entrenar).\n",
    "\n",
    "---\n",
    "\n",
    "Puede:\n",
    "\n",
    "- Utilizar GPT-4 / modelos más grandes (o cualquier «modelo experto») para **generar pares de preguntas y respuestas** a partir de documentos.\n",
    "- **Ajustar finamente un modelo de pesos abiertos más pequeño** en estos pares de preguntas y respuestas.\n",
    "- Mantener RAG también para inyectar **documentos muy recientes**.\n",
    "\n",
    "Resultado:\n",
    "- El modelo pequeño mejora en **jerga y estilo** gracias al ajuste fino.\n",
    "- RAG lo mantiene **actualizado** con nuevos documentos.\n",
    "\n",
    "En el resto de este cuaderno implementaremos:\n",
    "\n",
    "1. Un pequeño **canal RAG**.\n",
    "2. Un pequeño **ajuste fino LoRA**.\n",
    "3. Una rápida **comparación**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eeee931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "# !pip install -q \\\n",
    "#   torch \\\n",
    "#   transformers \\\n",
    "#   accelerate \\\n",
    "#   bitsandbytes \\\n",
    "#   peft \\\n",
    "#   sentence-transformers \\\n",
    "#   datasets \\\n",
    "#   scikit-learn \\\n",
    "#   faiss "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0e4164",
   "metadata": {},
   "source": [
    "### Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3488cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "from datasets import Dataset, load_dataset\n",
    "from pathlib import Path\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from pprint import pprint\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    GenerationConfig,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b311877a",
   "metadata": {},
   "source": [
    "### Configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d06e040",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"0\"\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:32\"\n",
    "torch.backends.cuda.matmul.fp32_precision = (\n",
    "    \"ieee\"  # torch.backends.cuda.matmul.allow_tf32 = True\n",
    ")\n",
    "torch.backends.cudnn.conv.fp32_precision = (\n",
    "    \"tf32\"  # torch.backends.cudnn.allow_tf32 = True\n",
    ")\n",
    "torch.cuda.empty_cache()\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11005e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__Python VERSION: 3.12.11 (main, Sep  5 2025, 19:35:43) [GCC 13.3.0]\n",
      "__pyTorch VERSION: 2.9.0+cu128\n",
      "__CUDA VERSION\n",
      "__CUDNN VERSION: 91002\n",
      "__Number CUDA Devices: 1\n",
      "__Devices\n",
      "Active CUDA Device: GPU 0\n",
      "Available devices  1\n",
      "Current cuda device  0\n"
     ]
    }
   ],
   "source": [
    "print(\"__Python VERSION:\", sys.version)\n",
    "print(\"__pyTorch VERSION:\", torch.__version__)\n",
    "print(\n",
    "    \"__CUDA VERSION\",\n",
    ")\n",
    "print(\"__CUDNN VERSION:\", torch.backends.cudnn.version())\n",
    "print(\"__Number CUDA Devices:\", torch.cuda.device_count())\n",
    "print(\"__Devices\")\n",
    "print(\"Active CUDA Device: GPU\", torch.cuda.current_device())\n",
    "print(\"Available devices \", torch.cuda.device_count())\n",
    "print(\"Current cuda device \", torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8af7ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov 19 12:37:58 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1650 Ti     Off |   00000000:01:00.0  On |                  N/A |\n",
      "| N/A   68C    P5              9W /   50W |     329MiB /   4096MiB |     26%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A     12943      G   /usr/bin/gnome-shell                           81MiB |\n",
      "|    0   N/A  N/A    265873      G   ...scord/260/usr/share/discord/Discord         68MiB |\n",
      "|    0   N/A  N/A    430612      G   /proc/self/exe                                172MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8b81482",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51598ba4",
   "metadata": {},
   "source": [
    "Vamos con un ejemplo pequeño"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29266f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_docs = [\n",
    "    # 1\n",
    "    \"\"\"OpenAI released a new model that improves reasoning on complex code and math problems. \n",
    "    The model is optimized for tool use and retrieval-augmented generation pipelines.\"\"\",\n",
    "    # 2\n",
    "    \"\"\"Google announced updates to its Vertex AI platform, making it easier to deploy and monitor \n",
    "    large language models at enterprise scale.\"\"\",\n",
    "    # 3\n",
    "    \"\"\"Meta open-sourced a set of Llama-based models with billions of parameters, \n",
    "    enabling researchers and companies to fine-tune them for their own use cases.\"\"\",\n",
    "    # 4\n",
    "    \"\"\"Microsoft integrated generative AI into its Office suite, adding features such as \n",
    "    AI-powered summarization, drafting assistance, and automatic meeting notes generation.\"\"\",\n",
    "    # 5\n",
    "    \"\"\"Amazon Web Services introduced cheaper GPU instances optimized for inference workloads \n",
    "    like chatbots, code assistants, real-time search, and document question-answering.\"\"\",\n",
    "    # 6\n",
    "    \"\"\"NVIDIA released new open-source libraries for accelerating transformer inference, \n",
    "    offering significant speedups on consumer GPUs like the RTX 4090.\"\"\",\n",
    "    # 7\n",
    "    \"\"\"Anthropic published a research paper describing improvements in constitutional AI, \n",
    "    focusing on scalable oversight and safer model behavior.\"\"\",\n",
    "    # 8\n",
    "    \"\"\"Apple reportedly began testing on-device LLMs for future iPhone models, enabling \n",
    "    private AI features such as offline summarization and personal context reasoning.\"\"\",\n",
    "    # 9\n",
    "    \"\"\"Hugging Face launched a new inference API tier with higher throughput and native \n",
    "    support for vLLM, making it cheaper to serve models like Mistral-7B and Llama-3-8B.\"\"\",\n",
    "    # 10\n",
    "    \"\"\"Mistral AI released Mixtral-8x22B, a sparse mixture-of-experts model offering state-of-the-art \n",
    "    performance while remaining efficient enough for commercial deployment.\"\"\",\n",
    "    # 11\n",
    "    \"\"\"IBM announced a partnership with NASA to fine-tune foundation models on geospatial data \n",
    "    to improve climate analysis, wildfire prediction, and satellite imagery classification.\"\"\",\n",
    "    # 12\n",
    "    \"\"\"Databricks released DBRX, a 132B-weight mixture-of-experts model trained on curated \n",
    "    scientific and enterprise datasets, outperforming models of similar size.\"\"\",\n",
    "    # 13\n",
    "    \"\"\"Stability AI introduced Stable Diffusion 3, featuring improved text-image alignment \n",
    "    and reduced hallucination in multilingual prompting scenarios.\"\"\",\n",
    "    # 14\n",
    "    \"\"\"Snowflake added native vector search capabilities, allowing enterprises to store embeddings \n",
    "    and run RAG pipelines directly on their data warehouse.\"\"\",\n",
    "    # 15\n",
    "    \"\"\"Cohere launched a secure enterprise-grade embedding model designed for document retrieval, \n",
    "    semantic search, and multi-lingual knowledge-base applications.\"\"\",\n",
    "    # 16\n",
    "    \"\"\"Red Hat announced AI-enhanced DevOps tooling, including automated deployment validation \n",
    "    powered by small specialized LLMs.\"\"\",\n",
    "    # 17\n",
    "    \"\"\"Salesforce updated Einstein GPT with better CRM-specific reasoning, including lead scoring, \n",
    "    automatic email drafting, and pipeline forecasting.\"\"\",\n",
    "    # 18\n",
    "    \"\"\"Dropbox introduced AI-powered universal search across files, documents, PDFs, and images, \n",
    "    enabling users to query semantic content instantly.\"\"\",\n",
    "    # 19\n",
    "    \"\"\"Slack rolled out AI summarization for channels and threads, automatically generating \n",
    "    daily digests and extracting key decisions from long discussions.\"\"\",\n",
    "    # 20\n",
    "    \"\"\"Zoom added real-time conversation translation and AI-based meeting action items, \n",
    "    powered by a fine-tuned multilingual transformer model.\"\"\",\n",
    "]\n",
    "\n",
    "corpus_titles = [\n",
    "    \"OpenAI releases new reasoning model\",\n",
    "    \"Google updates Vertex AI\",\n",
    "    \"Meta open-sources Llama models\",\n",
    "    \"Microsoft adds AI to Office\",\n",
    "    \"AWS introduces cheaper GPU instances\",\n",
    "    \"NVIDIA releases transformer acceleration libs\",\n",
    "    \"Anthropic improves constitutional AI\",\n",
    "    \"Apple tests on-device LLMs\",\n",
    "    \"Hugging Face launches new inference tier\",\n",
    "    \"Mistral releases Mixtral-8x22B\",\n",
    "    \"IBM partners with NASA on geospatial AI\",\n",
    "    \"Databricks releases DBRX\",\n",
    "    \"Stability AI releases SD3\",\n",
    "    \"Snowflake adds vector search\",\n",
    "    \"Cohere launches enterprise embedding model\",\n",
    "    \"Red Hat adds AI DevOps tools\",\n",
    "    \"Salesforce updates Einstein GPT\",\n",
    "    \"Dropbox adds AI universal search\",\n",
    "    \"Slack adds AI summaries\",\n",
    "    \"Zoom adds real-time AI translation\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58330e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dc2cc8",
   "metadata": {},
   "source": [
    "Realizamos el embedding de los documentos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d2ffe4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# small and fast embedding model (open weights)\n",
    "embedding_model_name = \"sentence-transformers/all-MiniLM-L6-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97a6f841",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = SentenceTransformer(model_name_or_path=embedding_model_name, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e592432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ef99cc70aac4017968c0d61a73a239b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute embeddings\n",
    "doc_embeddings = embedder.encode(\n",
    "    sentences=corpus_docs, \n",
    "    convert_to_numpy=True,\n",
    "    show_progress_bar=True,\n",
    "    device=device,\n",
    "    normalize_embeddings=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82482535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.05694531, -0.01272646, -0.06879752, ...,  0.05730383,\n",
       "          0.04768759,  0.00835872],\n",
       "        [-0.07661536, -0.08271152,  0.03887794, ..., -0.00933229,\n",
       "          0.05409345, -0.03391702],\n",
       "        [-0.03868605, -0.02878194, -0.02075998, ..., -0.04762491,\n",
       "         -0.01284006,  0.03692014],\n",
       "        ...,\n",
       "        [-0.02095782, -0.03330291, -0.04754037, ...,  0.04166466,\n",
       "          0.05232637,  0.02517612],\n",
       "        [-0.00392685, -0.02862822, -0.01042572, ...,  0.05525399,\n",
       "         -0.05279417, -0.02444052],\n",
       "        [-0.08633485, -0.04698378,  0.00952209, ...,  0.04447945,\n",
       "         -0.1053777 , -0.02525596]], dtype=float32),\n",
       " (20, 384))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_embeddings, doc_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426b09fb",
   "metadata": {},
   "source": [
    "Vamos a crear un índice FAISS para búsqueda eficiente de vecinos más cercanos y un indice por NearestNeighbors en sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bf41aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn\n",
    "nn_index = NearestNeighbors(n_neighbors=3, metric=\"cosine\")\n",
    "nn_index.fit(doc_embeddings)\n",
    "\n",
    "# Faiss\n",
    "faiss_emb = np.array(doc_embeddings).astype(\"float32\")\n",
    "faiss_index = faiss.IndexFlatIP(faiss_emb.shape[1])  # cosine similarity via inner product\n",
    "faiss.normalize_L2(faiss_emb)\n",
    "faiss_index.add(faiss_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e284facc",
   "metadata": {},
   "source": [
    "### RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8081088a",
   "metadata": {},
   "source": [
    "![Quant1](./Images/RAG.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c8cad9",
   "metadata": {},
   "source": [
    "Fuente: P. Iusztin & M. Labonne - LLM Engineer's Handbook - Chapter 4 - RAG Feature Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff963db0",
   "metadata": {},
   "source": [
    "Vamos a crear una función que nos genera la salida bruta (input+output) y la salida neta (output):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "782b9ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(model, tokenizer, prompt, max_length, max_new_tokens):\n",
    "    inputs = tokenizer(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "    ).to(device)\n",
    "\n",
    "    gen_config = GenerationConfig(\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=True,  # activa el muestreo aleatorio (sampling) en lugar de argmax\n",
    "        # necesario para que temperature / top_p tengan efecto\n",
    "        temperature=0.3,  # escala la \"suavidad\" del softmax\n",
    "        top_p=0.9,  # nucleus sampling: el modelo elige solo entre las palabras que\n",
    "        # acumulan el 90% de la probabilidad total (variable-size)\n",
    "        # top_k=50,        # OPCIONAL: limitar a las k palabras más probables\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(**inputs, generation_config=gen_config)\n",
    "\n",
    "    # Full decoded output (prompt + generated)\n",
    "    full_decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    # Only the continuation (generated tokens after the prompt)\n",
    "    generated_ids = output[0][inputs[\"input_ids\"].shape[1] :]\n",
    "    generated_decoded = tokenizer.decode(generated_ids, skip_special_tokens=True).strip()\n",
    "\n",
    "    return full_decoded, generated_decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94423eac",
   "metadata": {},
   "source": [
    "En la generación de texto, estos parámetros controlan cuánta **aleatoriedad**, **creatividad** o **determinismo** tendrá el modelo.\n",
    "\n",
    "**1. do_sample**\n",
    "Indica si el modelo debe usar muestreo aleatorio en lugar de escoger siempre la palabra más probable.\n",
    "\n",
    "`do_sample=False` → Decodificación determinista\n",
    "- El modelo siempre elige el token con mayor probabilidad (argmax).  \n",
    "- Equivale a *greedy decoding* o *beam search*.  \n",
    "- La salida es siempre igual para un mismo input.\n",
    "\n",
    "`do_sample=True` → Decodificación con muestreo\n",
    "- El modelo **no** toma siempre la palabra más probable.  \n",
    "- Muestra aleatoriamente según la distribución de probabilidades (softmax).  \n",
    "- Permite creatividad y variación.\n",
    "\n",
    "\n",
    "**2. Temperatura**\n",
    "La temperatura controla qué tan “plana” o “concentrada” es la distribución de probabilidades.\n",
    "\n",
    "Efectos prácticos:\n",
    "- **Temperatura baja (0.0 – 0.5):**  \n",
    "  Texto más determinista, formal, predecible.\n",
    "- **Temperatura media (0.7 – 1.0):**  \n",
    "  Buen balance entre coherencia y creatividad.\n",
    "- **Temperatura alta (≥1.2):**  \n",
    "  Texto muy creativo e impredecible.\n",
    "\n",
    "Interpretación intuitiva:\n",
    "“Más temperatura = más libertad para elegir palabras.”\n",
    "\n",
    "Matemáticamente:\n",
    "La temperatura \\(T\\) se aplica escalando los logits del modelo:\n",
    "\n",
    "$P(w_i) = \\frac{e^{z_i / T}}{\\sum_j e^{z_j / T}}$\n",
    "\n",
    "donde:\n",
    "- $z_i$ = logit del token \\(i\\)  \n",
    "- $T$ = temperatura\n",
    "\n",
    "\n",
    "**3. Top-p (Nucleus Sampling)**\n",
    "Top-p controla aleatoriedad seleccionando solo los tokens cuya **probabilidad acumulada** alcanza un umbral \\(p\\).\n",
    "\n",
    "Ejemplos:\n",
    "- **p = 0.5** → muy conservador  \n",
    "- **p = 0.9** → equilibrado (el más usado)  \n",
    "- **p = 0.95–0.99** → más creativo  \n",
    "\n",
    "Algoritmo:\n",
    "1. Ordenar los tokens por probabilidad:  \n",
    "   $P(w_1) \\ge P(w_2) \\ge \\dots \\ge P(w_n)$\n",
    "2. Construir el conjunto mínimo \\(S\\) tal que:  \n",
    "   $\\sum_{w_i \\in S} P(w_i) \\ge p$\n",
    "3. Hacer muestreo **solo dentro de \\(S\\)**:\n",
    "   $w \\sim \\text{Multinomial}\\big(P(w_i \\mid w_i \\in S)\\big)$\n",
    "\n",
    "Propiedad clave:\n",
    "El tamaño del conjunto **varía dinámicamente** según la distribución → más flexible que top-k.\n",
    "\n",
    "\n",
    "**4. Top-k**\n",
    "Top-k limita la elección a las **k palabras más probables**, descartando el resto.\n",
    "\n",
    "Ejemplos:\n",
    "- **k pequeño (10):** más control y coherencia.  \n",
    "- **k grande (50–100):** más diversidad.  \n",
    "- **k infinito / desactivado:** usa todos los tokens.\n",
    "\n",
    "Matemáticamente:\n",
    "Top-k actúa **antes del softmax**:\n",
    "\n",
    "1. Seleccionar los $k$ logits más altos.  \n",
    "2. Descartar los otros.  \n",
    "3. Aplicar softmax solo sobre esos $k$:\n",
    "\n",
    "$\n",
    "P(w_i)=\n",
    "\\begin{cases}\n",
    "\\frac{e^{z_i}}{\\sum_{j \\in \\text{top-k}} e^{z_j}} & i \\in \\text{top-k} \\\\\n",
    "0 & i \\notin \\text{top-k}\n",
    "\\end{cases}\n",
    "$\n",
    "\n",
    "\n",
    "**Resumen comparativo**\n",
    "\n",
    "| Parámetro | Qué controla | Tipo de límite |\n",
    "|-----------|--------------|----------------|\n",
    "| **do_sample** | Si hay muestreo o no | booleano |\n",
    "| **temperatura** | Suavidad de la distribución | escala continua |\n",
    "| **top-k** | Número fijo de candidatos | tamaño fijo |\n",
    "| **top-p** | Probabilidad acumulada | tamaño variable |\n",
    "\n",
    "**Top-p es más flexible e inteligente**, porque se adapta a la forma de la distribución.  \n",
    "**Top-k es más simple y estable**, pero rígido."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049ddc90",
   "metadata": {},
   "source": [
    "Ahora, una funcion retrieval de contexto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "122ee662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_context(question, k, backend):\n",
    "    \"\"\"\n",
    "    Retrieve top-k most similar documents using a selected backend:\n",
    "\n",
    "        - 'sklearn' : brute-force KNN using Scikit-Learn\n",
    "        - 'faiss'   : FAISS IndexFlatIP (optimized inner-product ANN)\n",
    "        - 'st'      : SentenceTransformers' own cosine-similarity search\n",
    "    \"\"\"\n",
    "\n",
    "    # Embed query → normalized vector (good for cosine similarity / inner product)\n",
    "    q_emb = embedder.encode(\n",
    "        [question], convert_to_numpy=True, normalize_embeddings=True\n",
    "    )\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 1) Scikit-Learn NearestNeighbors (exact search)\n",
    "    # ---------------------------------------------------------\n",
    "    if backend == \"sklearn\":\n",
    "        # Brute-force cosine similarity via sklearn's KNN search.\n",
    "        # Works well for small / medium corpora (<100k).\n",
    "        distances, indices = nn_index.kneighbors(q_emb, n_neighbors=k)\n",
    "        return [corpus_docs[i] for i in indices[0]]\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 2) FAISS (fast ANN search using inner product)\n",
    "    # ---------------------------------------------------------\n",
    "    elif backend == \"faiss\":\n",
    "        # FAISS expects float32 arrays.\n",
    "        q = q_emb.astype(\"float32\")\n",
    "        # Normalize for cosine similarity (since IP ≈ cosine when vectors are normalized)\n",
    "        faiss.normalize_L2(q)\n",
    "        # Very fast search (exact or ANN depending on index type)\n",
    "        distances, indices = faiss_index.search(q, k)\n",
    "        return [corpus_docs[i] for i in indices[0]]\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 3) SentenceTransformers semantic_search (exact cosine)\n",
    "    # ---------------------------------------------------------\n",
    "    elif backend == \"st\":\n",
    "        # Computes cosine similarity against all doc embeddings.\n",
    "        # This is brute-force but highly optimized in PyTorch/Numpy.\n",
    "        hits = util.semantic_search(q_emb, doc_embeddings, top_k=k)[0]\n",
    "        return [corpus_docs[hit[\"corpus_id\"]] for hit in hits]\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown retrieval backend: {backend}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d55c1d",
   "metadata": {},
   "source": [
    "Definimos 2 funciones: una que arma el prompt y otra que genera la respuesta del sistema RAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ffdbeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(question, tokenizer, contexts):\n",
    "    context_text = contexts[0]\n",
    "    prompt = f\"\"\"\n",
    "    You are a helpful assistant specialized in technology news.\n",
    "    Use ONLY the context below to answer the user question.\n",
    "    If the answer is not in the context, say I don't know.\n",
    "    Answer ONE short sentence. Do NOT repeat context or question\n",
    "    \\n  Question: {question}\n",
    "    \\n  Context: {context_text}\n",
    "    \\n Answer:\n",
    "    \"\"\"\n",
    "    count = len(tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"][0])\n",
    "    return prompt, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10fb66f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_answer(model, tokenizer, question, k, max_length, max_new_tokens, backend):\n",
    "    \"\"\"\n",
    "    Full RAG flow:\n",
    "    - Retrieve similar docs\n",
    "    - Build ChatML prompt with context\n",
    "    - Generate answer with the LLM\n",
    "    \"\"\"\n",
    "    contexts = retrieve_context(question, k, backend)\n",
    "    prompt, token_count = build_prompt(question, tokenizer, contexts)\n",
    "    full_output, gen_output = generate_answer(model, tokenizer, prompt, max_length, max_new_tokens)\n",
    "    return prompt, full_output, gen_output, contexts, token_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f27cb3",
   "metadata": {},
   "source": [
    "Elegimos un modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ba70968",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916e46e0",
   "metadata": {},
   "source": [
    "Link del modelo: https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f46d2e",
   "metadata": {},
   "source": [
    "Link de interes: https://codingscape.com/blog/llms-with-largest-context-windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20830fa7",
   "metadata": {},
   "source": [
    "Y un tokenizador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "785a9ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bdef92d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'▁investigation': 22522,\n",
       "  'MW': 25365,\n",
       "  '▁moder': 17768,\n",
       "  '▁#####': 16101,\n",
       "  '▁toute': 12563,\n",
       "  '/@': 29368,\n",
       "  '▁Boh': 17966,\n",
       "  '▁planet': 15754,\n",
       "  'എ': 31808,\n",
       "  'osoph': 7708,\n",
       "  'erna': 10989,\n",
       "  'vie': 25965,\n",
       "  '▁кате': 28868,\n",
       "  '▁Pan': 6518,\n",
       "  '▁charg': 9151,\n",
       "  '▁~': 3695,\n",
       "  'ward': 1328,\n",
       "  'mathchar': 22823,\n",
       "  'mathscr': 13002,\n",
       "  'augh': 6334,\n",
       "  '▁фон': 15779,\n",
       "  'address': 7328,\n",
       "  'вается': 25107,\n",
       "  '▁military': 9121,\n",
       "  '▁складі': 21887,\n",
       "  '▁Nr': 11100,\n",
       "  'anos': 16469,\n",
       "  'cid': 25232,\n",
       "  '▁dia': 9766,\n",
       "  'зд': 16598,\n",
       "  'nete': 18977,\n",
       "  'xls': 20267,\n",
       "  'issement': 11537,\n",
       "  '▁rgba': 24979,\n",
       "  'Credentials': 28037,\n",
       "  '▁рік': 24696,\n",
       "  '!!!': 21004,\n",
       "  'лова': 8163,\n",
       "  '▁Ist': 11066,\n",
       "  'úl': 25293,\n",
       "  '▁caught': 12624,\n",
       "  'rijk': 15986,\n",
       "  'ichte': 4458,\n",
       "  '▁Pse': 17646,\n",
       "  'bottom': 8968,\n",
       "  '▁ancient': 12297,\n",
       "  '`.': 1412,\n",
       "  '▁herm': 18606,\n",
       "  'Float': 11031,\n",
       "  'ню': 11128,\n",
       "  'agne': 5889,\n",
       "  '▁remove': 3349,\n",
       "  'material': 15388,\n",
       "  '▁Wien': 12899,\n",
       "  'most': 3242,\n",
       "  '▁uniformly': 26018,\n",
       "  'вет': 7616,\n",
       "  '▁dawn': 27470,\n",
       "  'approx': 14850,\n",
       "  '▁capable': 15390,\n",
       "  'ат': 12174,\n",
       "  'mat': 2922,\n",
       "  '▁reprezent': 17577,\n",
       "  'nych': 5909,\n",
       "  'engono': 23677,\n",
       "  '▁Ang': 3218,\n",
       "  '▁Like': 8502,\n",
       "  'က': 31371,\n",
       "  'asi': 6840,\n",
       "  'ieck': 16776,\n",
       "  '|}{': 29632,\n",
       "  '▁GND': 10453,\n",
       "  'vider': 5489,\n",
       "  '▁orbit': 16980,\n",
       "  '▁extracted': 23892,\n",
       "  'erd': 2018,\n",
       "  '▁Try': 3967,\n",
       "  '▁plusieurs': 10741,\n",
       "  'mult': 4713,\n",
       "  '▁California': 8046,\n",
       "  '▁приня': 17867,\n",
       "  'boost': 17079,\n",
       "  '▁кор': 13511,\n",
       "  'As': 2887,\n",
       "  '▁MTV': 28982,\n",
       "  '情': 30993,\n",
       "  '▁филь': 13320,\n",
       "  'museum': 25360,\n",
       "  '▁составе': 17932,\n",
       "  'ants': 1934,\n",
       "  '();': 890,\n",
       "  '▁село': 11166,\n",
       "  '▁materials': 17279,\n",
       "  '────': 19820,\n",
       "  'éch': 17192,\n",
       "  '▁nagy': 18338,\n",
       "  'ERT': 20161,\n",
       "  'Les': 24560,\n",
       "  'About': 28173,\n",
       "  '▁people': 2305,\n",
       "  '▁revolution': 19479,\n",
       "  '▁flat': 12151,\n",
       "  '▁changing': 6480,\n",
       "  '▁retra': 29578,\n",
       "  '▁suit': 14726,\n",
       "  '▁justice': 15426,\n",
       "  'YPE': 6959,\n",
       "  '▁Arthur': 11498,\n",
       "  'umph': 19149,\n",
       "  'front': 8862,\n",
       "  'Percent': 27933,\n",
       "  'zer': 3298,\n",
       "  '▁Profil': 23202,\n",
       "  '▁grow': 6548,\n",
       "  '▁turn': 2507,\n",
       "  'eurs': 11620,\n",
       "  '▁febrero': 9091,\n",
       "  'mt': 4378,\n",
       "  '▁sett': 3604,\n",
       "  '▁Review': 13957,\n",
       "  'browser': 15965,\n",
       "  'uniform': 29590,\n",
       "  '▁CGRect': 26064,\n",
       "  'isat': 24766,\n",
       "  '▁Firefox': 14418,\n",
       "  '▁compart': 29078,\n",
       "  '▁cí': 29491,\n",
       "  'hod': 24008,\n",
       "  'egy': 11125,\n",
       "  'aj': 1175,\n",
       "  'ifies': 11057,\n",
       "  '▁sam': 3514,\n",
       "  '’': 30010,\n",
       "  '▁built': 4240,\n",
       "  '▁powst': 24054,\n",
       "  'unction': 651,\n",
       "  '▁Open': 4673,\n",
       "  '▁Aff': 13737,\n",
       "  'lang': 3893,\n",
       "  '▁cot': 20118,\n",
       "  'ât': 10807,\n",
       "  '▁hierarchy': 21277,\n",
       "  '▁populated': 24146,\n",
       "  'imately': 15084,\n",
       "  '▁civile': 29338,\n",
       "  'чен': 4896,\n",
       "  'ton': 880,\n",
       "  'heiten': 21795,\n",
       "  '▁path': 2224,\n",
       "  '<0xD6>': 217,\n",
       "  'issues': 12175,\n",
       "  '▁Bu': 5373,\n",
       "  '$}}%': 25069,\n",
       "  '▁ident': 2893,\n",
       "  '▁elaborate': 19430,\n",
       "  '▁Zeitschrift': 29386,\n",
       "  \"▁'_\": 22868,\n",
       "  '▁fmt': 19200,\n",
       "  'seen': 28026,\n",
       "  '<<': 9314,\n",
       "  'pip': 13096,\n",
       "  '▁coverage': 23746,\n",
       "  '▁expl': 3902,\n",
       "  ')$$': 17085,\n",
       "  '▁fusion': 21736,\n",
       "  '▁inequality': 14585,\n",
       "  '▁praw': 20467,\n",
       "  '▁Step': 16696,\n",
       "  '▁находи': 14050,\n",
       "  'iet': 2035,\n",
       "  '▁regarding': 11211,\n",
       "  'пени': 25958,\n",
       "  'For': 2831,\n",
       "  '▁Tokyo': 20377,\n",
       "  'beans': 11700,\n",
       "  'вид': 20874,\n",
       "  'nx': 23818,\n",
       "  '▁Й': 14680,\n",
       "  '\\'\"': 11838,\n",
       "  'antin': 13027,\n",
       "  'bec': 19385,\n",
       "  '▁Wer': 8398,\n",
       "  '▁Lew': 11906,\n",
       "  'itte': 5388,\n",
       "  '▁Drop': 20724,\n",
       "  'essed': 11517,\n",
       "  '▁bou': 16380,\n",
       "  '▁times': 3064,\n",
       "  'icture': 4781,\n",
       "  'ny': 1460,\n",
       "  'det': 4801,\n",
       "  ')>': 15410,\n",
       "  '▁svo': 28316,\n",
       "  'oms': 4835,\n",
       "  'ould': 483,\n",
       "  'ITable': 12210,\n",
       "  '千': 31159,\n",
       "  '▁modifying': 23815,\n",
       "  '▁nyelven': 18030,\n",
       "  '▁premiers': 21426,\n",
       "  '▁Nathan': 27650,\n",
       "  '▁namely': 18451,\n",
       "  '▁edges': 12770,\n",
       "  'Directory': 9882,\n",
       "  '▁possibil': 27829,\n",
       "  '▁older': 9642,\n",
       "  '▁Sab': 11775,\n",
       "  'õ': 30084,\n",
       "  'Workbook': 26501,\n",
       "  'ocr': 8415,\n",
       "  'ген': 11933,\n",
       "  'тик': 29514,\n",
       "  '▁SSL': 17122,\n",
       "  '▁height': 3171,\n",
       "  '▁син': 24066,\n",
       "  'Int': 2928,\n",
       "  'plays': 12922,\n",
       "  'union': 13094,\n",
       "  'awn': 18101,\n",
       "  'parison': 20941,\n",
       "  '▁подо': 26388,\n",
       "  'ulu': 21528,\n",
       "  '北': 30662,\n",
       "  'ango': 4524,\n",
       "  'آ': 30726,\n",
       "  '▁disc': 2313,\n",
       "  '▁System': 2184,\n",
       "  'ּ': 30500,\n",
       "  '▁verschied': 14261,\n",
       "  '▁upper': 7568,\n",
       "  'ensemble': 24031,\n",
       "  'sterd': 14807,\n",
       "  'ř': 30047,\n",
       "  '▁collect': 6314,\n",
       "  'ные': 3029,\n",
       "  'ově': 27519,\n",
       "  '▁maintenance': 25413,\n",
       "  '▁overall': 12463,\n",
       "  '▁Тре': 27114,\n",
       "  'Defaults': 24863,\n",
       "  '▁corps': 14913,\n",
       "  'erta': 17951,\n",
       "  'jk': 25467,\n",
       "  '▁pup': 23449,\n",
       "  'Month': 13953,\n",
       "  'kehr': 10455,\n",
       "  '가': 30903,\n",
       "  'чай': 19424,\n",
       "  'ベ': 31061,\n",
       "  '▁\\\\]': 11424,\n",
       "  '▁cruel': 24116,\n",
       "  '▁estable': 19692,\n",
       "  'atta': 14975,\n",
       "  '▁retour': 18948,\n",
       "  '▁Bres': 27209,\n",
       "  'lista': 19641,\n",
       "  '▁lang': 6361,\n",
       "  ':%': 16664,\n",
       "  'док': 23604,\n",
       "  'aw': 1450,\n",
       "  '▁Unter': 5266,\n",
       "  'ゃ': 31312,\n",
       "  'leted': 22742,\n",
       "  '▁Microsoft': 7783,\n",
       "  'apan': 21419,\n",
       "  '▁representative': 21097,\n",
       "  '▁neutral': 21104,\n",
       "  '▁noch': 5440,\n",
       "  '▁een': 1739,\n",
       "  '▁Regarding': 29499,\n",
       "  'West': 16128,\n",
       "  '▁ranges': 20238,\n",
       "  '▁shock': 19253,\n",
       "  'DataSource': 15559,\n",
       "  'Vertical': 29270,\n",
       "  '▁Ana': 20367,\n",
       "  '▁Government': 10354,\n",
       "  'edor': 23286,\n",
       "  'fahrt': 29182,\n",
       "  '▁реа': 24548,\n",
       "  'へ': 31388,\n",
       "  'поли': 22929,\n",
       "  '▁Perú': 28686,\n",
       "  '▁sexual': 18287,\n",
       "  '▁cham': 11179,\n",
       "  '▁bi': 4768,\n",
       "  'pmatrix': 12571,\n",
       "  '▁fid': 25947,\n",
       "  'agas': 26712,\n",
       "  'ش': 30256,\n",
       "  '▁Chile': 13430,\n",
       "  '<0x66>': 105,\n",
       "  'nih': 13428,\n",
       "  'ithmetic': 18542,\n",
       "  '▁dabei': 17857,\n",
       "  '▁Circ': 12594,\n",
       "  'äu': 15583,\n",
       "  'detail': 16432,\n",
       "  '▁criter': 28770,\n",
       "  '▁cycl': 24502,\n",
       "  '▁LINQ': 28381,\n",
       "  'aments': 20060,\n",
       "  '▁acted': 27320,\n",
       "  '▁gauge': 22931,\n",
       "  'endance': 21642,\n",
       "  '▁politics': 22661,\n",
       "  '▁она': 15568,\n",
       "  '▁multimedia': 19004,\n",
       "  '▁consent': 20218,\n",
       "  'IMARY': 24480,\n",
       "  'дар': 5567,\n",
       "  'oking': 17223,\n",
       "  'кими': 21456,\n",
       "  '▁Oscar': 19054,\n",
       "  'move': 11631,\n",
       "  '▁Upper': 24929,\n",
       "  '▁mathematical': 19475,\n",
       "  '▁système': 21423,\n",
       "  'fér': 3666,\n",
       "  '▁Щ': 26975,\n",
       "  '▁Pay': 14617,\n",
       "  '▁mois': 17478,\n",
       "  'phia': 16271,\n",
       "  '▁indep': 5111,\n",
       "  'weise': 4506,\n",
       "  'algebra': 15742,\n",
       "  'visual': 20119,\n",
       "  '▁fled': 27481,\n",
       "  '▁{': 426,\n",
       "  'igkeiten': 29187,\n",
       "  '▁developer': 13897,\n",
       "  '▁reaction': 19848,\n",
       "  'url': 2271,\n",
       "  'mot': 14817,\n",
       "  '▁story': 5828,\n",
       "  '▁databases': 21218,\n",
       "  'locked': 29113,\n",
       "  'adora': 15441,\n",
       "  'Canvas': 21960,\n",
       "  'te': 371,\n",
       "  '▁victory': 15354,\n",
       "  '▁Cult': 7965,\n",
       "  '<0x04>': 7,\n",
       "  'layers': 29277,\n",
       "  '▁argued': 28705,\n",
       "  'ção': 2340,\n",
       "  'erst': 15714,\n",
       "  'Middle': 25411,\n",
       "  'decode': 13808,\n",
       "  'ws': 5652,\n",
       "  '▁champ': 18480,\n",
       "  'izard': 17909,\n",
       "  '▁calculations': 17203,\n",
       "  '▁Francis': 5845,\n",
       "  '▁invece': 24248,\n",
       "  '▁hang': 13958,\n",
       "  '▁signing': 26188,\n",
       "  '▁libro': 19366,\n",
       "  '▁liv': 7294,\n",
       "  'kt': 1193,\n",
       "  'rek': 22218,\n",
       "  '▁Exec': 11080,\n",
       "  '강': 31774,\n",
       "  '▁geg': 21598,\n",
       "  '▁који': 15279,\n",
       "  '<=': 14065,\n",
       "  'ideo': 3007,\n",
       "  '▁campaign': 11531,\n",
       "  '▁Guinea': 29252,\n",
       "  '▁alem': 20712,\n",
       "  'includes': 24572,\n",
       "  'azionale': 24916,\n",
       "  'рів': 12269,\n",
       "  '▁http': 1732,\n",
       "  '▁talent': 24242,\n",
       "  'kim': 20903,\n",
       "  '▁psych': 11643,\n",
       "  'endif': 15224,\n",
       "  'Logger': 16363,\n",
       "  '▁Bib': 19864,\n",
       "  'ragma': 23929,\n",
       "  '▁Fore': 28297,\n",
       "  '”,': 9363,\n",
       "  '▁equivalent': 7126,\n",
       "  '▁Сред': 25481,\n",
       "  '面': 30806,\n",
       "  '▁Change': 10726,\n",
       "  'itis': 23448,\n",
       "  'SQL': 4176,\n",
       "  ')$': 1262,\n",
       "  'cipl': 13326,\n",
       "  '▁sorrow': 28543,\n",
       "  '(\"<': 28945,\n",
       "  '▁Also': 3115,\n",
       "  '▁голов': 19311,\n",
       "  '▁Jed': 18847,\n",
       "  '▁»': 2047,\n",
       "  '▁mismo': 11329,\n",
       "  'Render': 10716,\n",
       "  '▁уз': 26008,\n",
       "  '▁представи': 21768,\n",
       "  '泉': 31637,\n",
       "  '방': 31945,\n",
       "  '▁Arc': 22711,\n",
       "  '▁проис': 23061,\n",
       "  'Build': 8893,\n",
       "  '▁tarde': 17666,\n",
       "  'мб': 16001,\n",
       "  'edge': 12864,\n",
       "  '▁mud': 17439,\n",
       "  'iversity': 24974,\n",
       "  '▁OpenGL': 29508,\n",
       "  '▁institution': 12666,\n",
       "  '▁stands': 15028,\n",
       "  '▁znaj': 18657,\n",
       "  'zech': 12357,\n",
       "  '▁reverse': 11837,\n",
       "  '▁IDE': 15004,\n",
       "  '▁bra': 4105,\n",
       "  '▁satisfies': 17150,\n",
       "  'Stack': 7264,\n",
       "  '▁eigenvalues': 25973,\n",
       "  'herit': 27069,\n",
       "  '▁proc': 9580,\n",
       "  '▁manus': 18831,\n",
       "  '<0xAE>': 177,\n",
       "  '▁embed': 8297,\n",
       "  '▁Order': 8170,\n",
       "  '▁Jen': 21116,\n",
       "  '▁deprec': 16460,\n",
       "  'ским': 9187,\n",
       "  'chn': 3049,\n",
       "  '▁Basically': 13702,\n",
       "  '▁drive': 7899,\n",
       "  '▁Enllaços': 26821,\n",
       "  'ésie': 29831,\n",
       "  'quipe': 11435,\n",
       "  '-%': 19222,\n",
       "  '▁Names': 14706,\n",
       "  'ਸ': 31691,\n",
       "  '▁gold': 7684,\n",
       "  'rock': 20821,\n",
       "  '▁капи': 28850,\n",
       "  'ber': 495,\n",
       "  '崎': 31416,\n",
       "  '▁stream': 4840,\n",
       "  'uge': 5710,\n",
       "  '保': 30982,\n",
       "  'Mock': 18680,\n",
       "  '▁Arab': 10387,\n",
       "  'gebracht': 28713,\n",
       "  'сно': 9627,\n",
       "  '▁posterior': 13446,\n",
       "  '▁versión': 18648,\n",
       "  '▁komt': 23159,\n",
       "  'ASS': 22933,\n",
       "  'lower': 13609,\n",
       "  'ępu': 21917,\n",
       "  '▁XIXe': 28250,\n",
       "  'cente': 21450,\n",
       "  '▀': 30676,\n",
       "  'Theorem': 28831,\n",
       "  'ственных': 26090,\n",
       "  'near': 28502,\n",
       "  'Encoding': 14934,\n",
       "  'digit': 26204,\n",
       "  '▁relationships': 21702,\n",
       "  '▁Jak': 13669,\n",
       "  'Section': 13438,\n",
       "  '▁пло': 11366,\n",
       "  'ière': 5289,\n",
       "  'izzazione': 21146,\n",
       "  '▁Range': 12146,\n",
       "  '▁Mur': 7487,\n",
       "  '▁sia': 14718,\n",
       "  'ський': 6240,\n",
       "  '▁Original': 8533,\n",
       "  'navigation': 15466,\n",
       "  '!”': 8530,\n",
       "  '▁disabled': 12708,\n",
       "  'uka': 22971,\n",
       "  'urn': 595,\n",
       "  '▁людя': 18418,\n",
       "  'AF': 5098,\n",
       "  '<0xD3>': 214,\n",
       "  'fail': 14057,\n",
       "  'uliar': 17709,\n",
       "  'Chain': 14688,\n",
       "  'Cache': 10408,\n",
       "  '▁внут': 27165,\n",
       "  'quet': 12621,\n",
       "  '▁very': 1407,\n",
       "  '┃': 31588,\n",
       "  '<0xA8>': 171,\n",
       "  '▁MM': 28880,\n",
       "  '▁volumes': 18167,\n",
       "  'inds': 12772,\n",
       "  '女': 30647,\n",
       "  '▁collapse': 24382,\n",
       "  '▁WPF': 23678,\n",
       "  '▁зо': 25687,\n",
       "  '▁mill': 3533,\n",
       "  'dbo': 21627,\n",
       "  '▁Something': 12538,\n",
       "  'et': 300,\n",
       "  'nl': 12938,\n",
       "  '<0xEB>': 238,\n",
       "  'Atlas': 27753,\n",
       "  '▁Het': 5937,\n",
       "  '▁Ku': 18185,\n",
       "  '▁uz': 27296,\n",
       "  '▁correl': 8855,\n",
       "  'Reset': 27175,\n",
       "  'ED': 3352,\n",
       "  'concurrent': 19279,\n",
       "  '▁DNA': 25348,\n",
       "  'ifferent': 15622,\n",
       "  '▁са': 2489,\n",
       "  '<0x7C>': 127,\n",
       "  'imp': 6574,\n",
       "  'ҡ': 31892,\n",
       "  'eor': 22241,\n",
       "  'spaces': 22854,\n",
       "  '▁laten': 23316,\n",
       "  '▁пр': 12781,\n",
       "  'F': 29943,\n",
       "  'AtIndex': 16686,\n",
       "  'ingham': 16094,\n",
       "  'il': 309,\n",
       "  'OL': 5607,\n",
       "  '▁квітня': 26334,\n",
       "  '▁Black': 6054,\n",
       "  'Mutable': 15211,\n",
       "  'cript': 924,\n",
       "  '▁Wohn': 21119,\n",
       "  'нина': 23508,\n",
       "  'CK': 7077,\n",
       "  'series': 13757,\n",
       "  '▁img': 10153,\n",
       "  'select': 2622,\n",
       "  '▁ends': 10614,\n",
       "  'furt': 13065,\n",
       "  'Ç': 30219,\n",
       "  '▁pela': 10571,\n",
       "  '()->': 13539,\n",
       "  'Da': 27838,\n",
       "  '▁UITableView': 20197,\n",
       "  'pois': 17376,\n",
       "  '▁PATH': 23611,\n",
       "  '▁bezeichnet': 11138,\n",
       "  '▁wicht': 21393,\n",
       "  '▁cors': 27672,\n",
       "  'Vorlage': 17576,\n",
       "  'webkit': 14085,\n",
       "  '▁Ис': 23695,\n",
       "  '▁ella': 16634,\n",
       "  'czas': 14286,\n",
       "  '▁Wes': 23976,\n",
       "  'cious': 8802,\n",
       "  'ほ': 31938,\n",
       "  '▁meet': 5870,\n",
       "  'ns': 1983,\n",
       "  '▁dieses': 18947,\n",
       "  'etro': 29551,\n",
       "  'Message': 3728,\n",
       "  'istiche': 29000,\n",
       "  'ме': 1488,\n",
       "  '▁corr': 27760,\n",
       "  'ystycz': 28021,\n",
       "  '▁printing': 14010,\n",
       "  'braries': 8464,\n",
       "  '▁jsou': 17228,\n",
       "  '▁bec': 1172,\n",
       "  'istence': 11416,\n",
       "  '▁denen': 17209,\n",
       "  'Changed': 7590,\n",
       "  'сла': 12329,\n",
       "  'processing': 19170,\n",
       "  'endra': 25404,\n",
       "  '▁Po': 3929,\n",
       "  '▁diferentes': 20506,\n",
       "  '▁Пра': 17913,\n",
       "  'appy': 14862,\n",
       "  'available': 16515,\n",
       "  'plugins': 12800,\n",
       "  '▁okay': 20759,\n",
       "  'ific': 928,\n",
       "  'ation': 362,\n",
       "  'odo': 8144,\n",
       "  'GL': 7239,\n",
       "  '▁propriet': 24440,\n",
       "  '▁Therefore': 7857,\n",
       "  '▁large': 2919,\n",
       "  '▁ajax': 9349,\n",
       "  '▁Gr': 1632,\n",
       "  '▁ORDER': 15606,\n",
       "  '▁metric': 12714,\n",
       "  '▁obras': 20589,\n",
       "  'blast': 23190,\n",
       "  '▁как': 5413,\n",
       "  'III': 5287,\n",
       "  'ostream': 18123,\n",
       "  'ános': 27118,\n",
       "  '▁sought': 18365,\n",
       "  '服': 31520,\n",
       "  'an': 273,\n",
       "  '▁situ': 2990,\n",
       "  'та': 676,\n",
       "  '▁expanded': 17832,\n",
       "  '▁esper': 17451,\n",
       "  '▁rodz': 17453,\n",
       "  '▁оконча': 27972,\n",
       "  '▁Stage': 24906,\n",
       "  '两': 31977,\n",
       "  '▁международ': 25075,\n",
       "  '▁pm': 26354,\n",
       "  'taire': 19073,\n",
       "  'е': 29919,\n",
       "  '▁phys': 4824,\n",
       "  '▁vá': 9366,\n",
       "  'asons': 7040,\n",
       "  '▁bomb': 13585,\n",
       "  '▁trouble': 7458,\n",
       "  '▁study': 6559,\n",
       "  'itories': 20106,\n",
       "  'Case': 8259,\n",
       "  'س': 30198,\n",
       "  'ako': 4614,\n",
       "  'yman': 21909,\n",
       "  'бю': 24524,\n",
       "  'ząt': 24822,\n",
       "  'екси': 9896,\n",
       "  'swer': 581,\n",
       "  '▁dispatch': 13916,\n",
       "  'ver': 369,\n",
       "  'Sito': 28409,\n",
       "  'zar': 26687,\n",
       "  '▁kró': 27638,\n",
       "  '\");': 1496,\n",
       "  'ências': 9339,\n",
       "  '▁Non': 10050,\n",
       "  '▁три': 10357,\n",
       "  '▁local': 1887,\n",
       "  'ández': 19610,\n",
       "  '▁powiecie': 29640,\n",
       "  'nego': 10313,\n",
       "  '之': 30577,\n",
       "  '▁scen': 5763,\n",
       "  '▁millones': 26727,\n",
       "  'aries': 4314,\n",
       "  '▁Rain': 21431,\n",
       "  'нан': 11659,\n",
       "  '▁disapp': 8796,\n",
       "  'unas': 17496,\n",
       "  '▁\"-': 11663,\n",
       "  '▁egy': 5524,\n",
       "  'ensoort': 26006,\n",
       "  'ether': 1979,\n",
       "  'text': 726,\n",
       "  '▁hon': 4207,\n",
       "  '▁TextView': 19633,\n",
       "  '음': 31966,\n",
       "  '▁lands': 12625,\n",
       "  '▁house': 3699,\n",
       "  'ザ': 31123,\n",
       "  'ку': 1382,\n",
       "  'marker': 22976,\n",
       "  '▁directeur': 26114,\n",
       "  'ami': 4479,\n",
       "  '▁Har': 3536,\n",
       "  '▁Identity': 27486,\n",
       "  'acion': 16337,\n",
       "  '▁Import': 16032,\n",
       "  'Cla': 20216,\n",
       "  'scene': 24645,\n",
       "  '▁High': 5057,\n",
       "  'ських': 12581,\n",
       "  '▁Six': 18372,\n",
       "  '▁Литература': 15799,\n",
       "  'ituto': 21059,\n",
       "  '▁proph': 27953,\n",
       "  'ibil': 13017,\n",
       "  '▁has': 756,\n",
       "  'omin': 5817,\n",
       "  '▁ро': 1561,\n",
       "  'olen': 18975,\n",
       "  '▁Lost': 25133,\n",
       "  'century': 27371,\n",
       "  'subset': 6484,\n",
       "  '▁Fried': 6662,\n",
       "  '▁Kn': 8360,\n",
       "  '▁pattern': 4766,\n",
       "  'licit': 4019,\n",
       "  'ightarrow': 28142,\n",
       "  '▁ceased': 24886,\n",
       "  'asto': 24186,\n",
       "  'wise': 3538,\n",
       "  '▁voix': 22759,\n",
       "  'unci': 11173,\n",
       "  '▁части': 9809,\n",
       "  '得': 31050,\n",
       "  'create': 3258,\n",
       "  'month': 10874,\n",
       "  'have': 17532,\n",
       "  '▁Format': 19191,\n",
       "  'development': 25431,\n",
       "  '▁Squad': 18827,\n",
       "  'jest': 29618,\n",
       "  '▁weer': 24375,\n",
       "  '▁races': 19830,\n",
       "  'phone': 6710,\n",
       "  '▁topological': 25002,\n",
       "  '▁Additionally': 19814,\n",
       "  'nc': 17608,\n",
       "  '▁цар': 21350,\n",
       "  '▁vin': 13848,\n",
       "  '▁destroyed': 14416,\n",
       "  '▁localhost': 15683,\n",
       "  'ef': 1389,\n",
       "  '▁conser': 21929,\n",
       "  '▁róż': 28801,\n",
       "  '▁Far': 8413,\n",
       "  'virt': 15389,\n",
       "  'urity': 7710,\n",
       "  '▁объ': 11779,\n",
       "  'interno': 27160,\n",
       "  'ocy': 22502,\n",
       "  'jo': 2212,\n",
       "  '▁recom': 27878,\n",
       "  'aining': 17225,\n",
       "  '▁reboot': 22538,\n",
       "  '▁pack': 4870,\n",
       "  '▁kg': 12118,\n",
       "  'Des': 4002,\n",
       "  'ръ': 19003,\n",
       "  '▁Уи': 22505,\n",
       "  '▁rép': 25179,\n",
       "  '▁safety': 15332,\n",
       "  '▁civ': 14175,\n",
       "  '▁april': 17187,\n",
       "  '▁ul': 9238,\n",
       "  '▁jun': 4707,\n",
       "  'ies': 583,\n",
       "  'Received': 29816,\n",
       "  'thead': 19081,\n",
       "  '▁notify': 26051,\n",
       "  '▁Bin': 27662,\n",
       "  '▁anom': 29342,\n",
       "  'sak': 27909,\n",
       "  'udni': 25113,\n",
       "  'ologia': 10020,\n",
       "  '▁records': 6475,\n",
       "  '▁females': 24473,\n",
       "  'ikus': 17342,\n",
       "  'SERVER': 18603,\n",
       "  '▁trick': 8938,\n",
       "  '▁rational': 17903,\n",
       "  'Paint': 28939,\n",
       "  '▁zar': 21370,\n",
       "  'Channel': 13599,\n",
       "  'pic': 16447,\n",
       "  'ieval': 16837,\n",
       "  'features': 22100,\n",
       "  'Module': 7355,\n",
       "  'ihe': 18019,\n",
       "  '⌘': 31418,\n",
       "  '▁planned': 20458,\n",
       "  '▁velocity': 12885,\n",
       "  'nitz': 29204,\n",
       "  '▁sort': 2656,\n",
       "  'ucha': 26609,\n",
       "  '▁implicit': 12235,\n",
       "  'Ad': 3253,\n",
       "  'Of': 2776,\n",
       "  '▁US': 3148,\n",
       "  '▁folgender': 27687,\n",
       "  '>': 29958,\n",
       "  'hand': 3179,\n",
       "  'Studio': 28867,\n",
       "  'Bl': 10358,\n",
       "  '▁nob': 22182,\n",
       "  '▁svg': 25773,\n",
       "  '{{': 6224,\n",
       "  'ECK': 16658,\n",
       "  'lieder': 16820,\n",
       "  'ilib': 15943,\n",
       "  '▁advantage': 10631,\n",
       "  '▁ору': 28659,\n",
       "  'neg': 10052,\n",
       "  '▁Austria': 17362,\n",
       "  '▁autory': 20070,\n",
       "  '▁ssh': 13927,\n",
       "  '<0x11>': 20,\n",
       "  '▁дія': 22943,\n",
       "  '<0xDE>': 225,\n",
       "  '▁bel': 1339,\n",
       "  'permission': 16074,\n",
       "  '福': 31121,\n",
       "  '▁sink': 28169,\n",
       "  'sq': 3044,\n",
       "  '▁>>>': 8653,\n",
       "  '▁Syn': 10829,\n",
       "  '▁фа': 6725,\n",
       "  '▁indeed': 6200,\n",
       "  '▁де': 2263,\n",
       "  'onel': 11064,\n",
       "  '▁Tang': 27378,\n",
       "  '▁serie': 7080,\n",
       "  'ogene': 16603,\n",
       "  'HER': 4448,\n",
       "  'каде': 12832,\n",
       "  'structure': 23905,\n",
       "  'ɲ': 30849,\n",
       "  '好': 31076,\n",
       "  '▁issue': 2228,\n",
       "  '▁upp': 10282,\n",
       "  'Access': 6638,\n",
       "  '▁Despite': 19454,\n",
       "  '▁gh': 24170,\n",
       "  '▁Buch': 10586,\n",
       "  '▁markers': 29320,\n",
       "  '<0x37>': 58,\n",
       "  '▁ак': 20356,\n",
       "  '▁def': 822,\n",
       "  'threads': 28993,\n",
       "  '▁secret': 7035,\n",
       "  'hspace': 14158,\n",
       "  '▁Sing': 6106,\n",
       "  '▁Later': 12699,\n",
       "  'attro': 19114,\n",
       "  'four': 17823,\n",
       "  '▁plate': 15284,\n",
       "  '▁Бу': 9746,\n",
       "  '▁mystery': 29236,\n",
       "  '▁Vertrag': 29396,\n",
       "  '▁Boliv': 25765,\n",
       "  '▁Ren': 7493,\n",
       "  'dart': 11353,\n",
       "  '▁symmetry': 18446,\n",
       "  '▁anticip': 23483,\n",
       "  '▁reject': 12560,\n",
       "  '▁stdout': 27591,\n",
       "  '▁women': 5866,\n",
       "  'ș': 30065,\n",
       "  'und': 870,\n",
       "  '▁th': 266,\n",
       "  'ech': 5309,\n",
       "  '▁attitude': 26309,\n",
       "  'woord': 25317,\n",
       "  'ocs': 12332,\n",
       "  '▁transmission': 22713,\n",
       "  'quick': 24561,\n",
       "  '`)': 6348,\n",
       "  'mathfrak': 7237,\n",
       "  'ником': 14083,\n",
       "  '▁nederbörd': 17299,\n",
       "  '▁SY': 28962,\n",
       "  '<0x96>': 153,\n",
       "  '▁Bug': 28209,\n",
       "  'Inf': 25433,\n",
       "  '}}}\\\\': 20388,\n",
       "  'ishing': 14424,\n",
       "  'ـ': 30400,\n",
       "  '▁janvier': 8891,\n",
       "  '▁agree': 8661,\n",
       "  '▁%.': 18695,\n",
       "  '▁learn': 5110,\n",
       "  'ョ': 30907,\n",
       "  '▁Bass': 17328,\n",
       "  'ímp': 19381,\n",
       "  '▁Verwalt': 19764,\n",
       "  '▁Schön': 28565,\n",
       "  '▁Cover': 26428,\n",
       "  '▁distinguished': 20660,\n",
       "  'ieg': 5876,\n",
       "  '▁contributions': 20706,\n",
       "  \"='\": 2433,\n",
       "  '▁пол': 7372,\n",
       "  'вор': 14593,\n",
       "  'mysq': 19268,\n",
       "  '▁attach': 10641,\n",
       "  '▁credit': 16200,\n",
       "  'ython': 1656,\n",
       "  'хе': 14417,\n",
       "  'student': 18945,\n",
       "  '▁tec': 13784,\n",
       "  '▁ambos': 27727,\n",
       "  '▁forme': 13618,\n",
       "  '▁settled': 17141,\n",
       "  'slow': 28544,\n",
       "  '▁Dem': 4432,\n",
       "  '▁Laura': 21671,\n",
       "  '▁comes': 5304,\n",
       "  '▁Eva': 27040,\n",
       "  '﹕': 30375,\n",
       "  'lywood': 16239,\n",
       "  'second': 7496,\n",
       "  '▁gegenüber': 26479,\n",
       "  '▁fame': 27965,\n",
       "  '▁servants': 26202,\n",
       "  'rough': 10573,\n",
       "  '▁Ir': 6600,\n",
       "  '▁gross': 22683,\n",
       "  'AT': 1299,\n",
       "  '▁Pablo': 24770,\n",
       "  '▁dom': 2432,\n",
       "  '▁Video': 13987,\n",
       "  'ers': 414,\n",
       "  '▁Anti': 18473,\n",
       "  'zig': 8923,\n",
       "  'ienie': 23898,\n",
       "  'ubuntu': 8767,\n",
       "  '▁oppos': 9209,\n",
       "  '▁ps': 6529,\n",
       "  '▁clés': 25766,\n",
       "  'world': 11526,\n",
       "  '▁świat': 27713,\n",
       "  '▁crash': 8095,\n",
       "  '▁zou': 15367,\n",
       "  'Gen': 15462,\n",
       "  'va': 1564,\n",
       "  '▁hydro': 17546,\n",
       "  'ờ': 30997,\n",
       "  '▁svil': 21927,\n",
       "  'rés': 19199,\n",
       "  'ange': 927,\n",
       "  '▁Swift': 14156,\n",
       "  '▁premier': 7017,\n",
       "  'Match': 9652,\n",
       "  'cl': 695,\n",
       "  '▁населения': 18670,\n",
       "  'uuid': 25118,\n",
       "  '▁théâtre': 25574,\n",
       "  '▁Pick': 23868,\n",
       "  'role': 12154,\n",
       "  'ptr': 7414,\n",
       "  '▁tud': 26992,\n",
       "  'delta': 4181,\n",
       "  '،': 31116,\n",
       "  '▁documentation': 5106,\n",
       "  '▁cand': 23794,\n",
       "  '▁followed': 5643,\n",
       "  'this': 1366,\n",
       "  '▁Man': 2315,\n",
       "  '▁roce': 10155,\n",
       "  'AM': 5194,\n",
       "  '▁Bez': 14691,\n",
       "  '▁período': 24685,\n",
       "  'occup': 16770,\n",
       "  '▁Derby': 29520,\n",
       "  'ア': 30310,\n",
       "  '▁Lane': 23841,\n",
       "  'tri': 3626,\n",
       "  '\\\\%': 8958,\n",
       "  '▁subm': 11834,\n",
       "  'Full': 13658,\n",
       "  '▁original': 2441,\n",
       "  '▁->': 1599,\n",
       "  '▁Province': 17325,\n",
       "  '▁drum': 24103,\n",
       "  '▁amaz': 21863,\n",
       "  '▁prima': 7233,\n",
       "  'Man': 2517,\n",
       "  '▁PA': 17687,\n",
       "  'volution': 4068,\n",
       "  'kw': 11022,\n",
       "  'feld': 10612,\n",
       "  '、': 30330,\n",
       "  '▁repres': 10981,\n",
       "  'call': 4804,\n",
       "  'terne': 11154,\n",
       "  '▁Gaz': 15853,\n",
       "  'para': 22752,\n",
       "  'eign': 7577,\n",
       "  '▁simultane': 16991,\n",
       "  '\\\\|_{': 22772,\n",
       "  '▁Weg': 17412,\n",
       "  '▁ev': 3415,\n",
       "  'p': 29886,\n",
       "  '▁eran': 14960,\n",
       "  'ourse': 10242,\n",
       "  '▁hack': 15833,\n",
       "  'ement': 882,\n",
       "  '▁Kaz': 15198,\n",
       "  '▁increasing': 10231,\n",
       "  '▁Ama': 11562,\n",
       "  '▁européenne': 29211,\n",
       "  '▁paragraph': 14880,\n",
       "  'туа': 29412,\n",
       "  '▁readable': 19909,\n",
       "  'ebook': 19273,\n",
       "  'then': 6098,\n",
       "  '▁Napoleon': 24265,\n",
       "  'readsheet': 27844,\n",
       "  'nea': 14011,\n",
       "  '▁repository': 9810,\n",
       "  'Қ': 30925,\n",
       "  '▁jour': 8694,\n",
       "  '运': 31894,\n",
       "  '▁Landes': 10089,\n",
       "  ...},\n",
       " 32000)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab, tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fa3656",
   "metadata": {},
   "source": [
    "### Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c46097",
   "metadata": {},
   "source": [
    "Para hacer mas eficiente el worfklow vamos a realizar 'quantization'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7bb5c5",
   "metadata": {},
   "source": [
    "![Quant1](./Images/Quant1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a1661f",
   "metadata": {},
   "source": [
    "![Quant1](./Images/Quant2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41ba940",
   "metadata": {},
   "source": [
    "Fuente: P. Iusztin & M. Labonne - LLM Engineer's Handbook - Chapter 8 - Inference Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "887c28ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-bit quantization config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f2f763",
   "metadata": {},
   "source": [
    "Definimos el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "690e4377",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "705f046c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0-21): 22 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=2048, out_features=256, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=2048, out_features=256, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear4bit(in_features=2048, out_features=5632, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=2048, out_features=5632, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=5632, out_features=2048, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((2048,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aed6f683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===========================================================================\n",
       "Layer (type:depth-idx)                             Param #\n",
       "===========================================================================\n",
       "LlamaForCausalLM                                   --\n",
       "├─LlamaModel: 1-1                                  --\n",
       "│    └─Embedding: 2-1                              65,536,000\n",
       "│    └─ModuleList: 2-2                             --\n",
       "│    │    └─LlamaDecoderLayer: 3-1                 22,024,192\n",
       "│    │    └─LlamaDecoderLayer: 3-2                 22,024,192\n",
       "│    │    └─LlamaDecoderLayer: 3-3                 22,024,192\n",
       "│    │    └─LlamaDecoderLayer: 3-4                 22,024,192\n",
       "│    │    └─LlamaDecoderLayer: 3-5                 22,024,192\n",
       "│    │    └─LlamaDecoderLayer: 3-6                 22,024,192\n",
       "│    │    └─LlamaDecoderLayer: 3-7                 22,024,192\n",
       "│    │    └─LlamaDecoderLayer: 3-8                 22,024,192\n",
       "│    │    └─LlamaDecoderLayer: 3-9                 22,024,192\n",
       "│    │    └─LlamaDecoderLayer: 3-10                22,024,192\n",
       "│    │    └─LlamaDecoderLayer: 3-11                22,024,192\n",
       "│    │    └─LlamaDecoderLayer: 3-12                22,024,192\n",
       "│    │    └─LlamaDecoderLayer: 3-13                22,024,192\n",
       "│    │    └─LlamaDecoderLayer: 3-14                22,024,192\n",
       "│    │    └─LlamaDecoderLayer: 3-15                22,024,192\n",
       "│    │    └─LlamaDecoderLayer: 3-16                22,024,192\n",
       "│    │    └─LlamaDecoderLayer: 3-17                22,024,192\n",
       "│    │    └─LlamaDecoderLayer: 3-18                22,024,192\n",
       "│    │    └─LlamaDecoderLayer: 3-19                22,024,192\n",
       "│    │    └─LlamaDecoderLayer: 3-20                22,024,192\n",
       "│    │    └─LlamaDecoderLayer: 3-21                22,024,192\n",
       "│    │    └─LlamaDecoderLayer: 3-22                22,024,192\n",
       "│    └─LlamaRMSNorm: 2-3                           2,048\n",
       "│    └─LlamaRotaryEmbedding: 2-4                   --\n",
       "├─Linear: 1-2                                      65,536,000\n",
       "===========================================================================\n",
       "Total params: 615,606,272\n",
       "Trainable params: 131,164,160\n",
       "Non-trainable params: 484,442,112\n",
       "==========================================================================="
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(base_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a365d77",
   "metadata": {},
   "source": [
    "Probemos el sistema RAG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11820608",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Which company open-sourced Llama-based models and for what purpose?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "52a98110",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt, raw_answer, answer, ctx, token_count = rag_answer(\n",
    "    base_model, tokenizer, question, 3, 256, 128, \"faiss\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a203a6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt: \n",
      "    You are a helpful assistant specialized in technology news.\n",
      "    Use ONLY the context below to answer the user question.\n",
      "    If the answer is not in the context, say I don't know.\n",
      "    Answer ONE short sentence. Do NOT repeat context or question\n",
      "    \n",
      "  Question: Which company open-sourced Llama-based models and for what purpose?\n",
      "    \n",
      "  Context: Meta open-sourced a set of Llama-based models with billions of parameters, \n",
      "    enabling researchers and companies to fine-tune them for their own use cases.\n",
      "    \n",
      " Answer:\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPrompt:\", prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2d7bcfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt token count: 140\n"
     ]
    }
   ],
   "source": [
    "print(\"Prompt token count:\", token_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1f01ae20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Contexts:\n",
      "\n",
      "--- Context 1 ---\n",
      "Meta open-sourced a set of Llama-based models with billions of parameters, \n",
      "    enabling researchers and companies to fine-tune them for their own use cases. \n",
      "\n",
      "--- Context 2 ---\n",
      "Hugging Face launched a new inference API tier with higher throughput and native \n",
      "    support for vLLM, making it cheaper to serve models like Mistral-7B and Llama-3-8B. \n",
      "\n",
      "--- Context 3 ---\n",
      "Apple reportedly began testing on-device LLMs for future iPhone models, enabling \n",
      "    private AI features such as offline summarization and personal context reasoning. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Retrieved Contexts:\\n\")\n",
    "for i, c in enumerate(ctx, 1):\n",
    "    print(f\"--- Context {i} ---\")\n",
    "    print(c.strip(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e767601b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw RAG Answer: \n",
      "    You are a helpful assistant specialized in technology news.\n",
      "    Use ONLY the context below to answer the user question.\n",
      "    If the answer is not in the context, say I don't know.\n",
      "    Answer ONE short sentence. Do NOT repeat context or question\n",
      "    \n",
      "  Question: Which company open-sourced Llama-based models and for what purpose?\n",
      "    \n",
      "  Context: Meta open-sourced a set of Llama-based models with billions of parameters, \n",
      "    enabling researchers and companies to fine-tune them for their own use cases.\n",
      "    \n",
      " Answer:\n",
      "     Meta has open-sourced a set of Llama-based models with billions of parameters, \n",
      "     enabling researchers and companies to fine-tune them for their own use cases.\n",
      "     The models are designed for a variety of tasks, including image classification, object detection, and semantic segmentation.\n",
      "     The open-sourcing of these models is a significant step towards making AI more accessible and useful for a wider range of users.\n"
     ]
    }
   ],
   "source": [
    "print(\"Raw RAG Answer:\", raw_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "50d04d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Answer:\n",
      " Meta has open-sourced a set of Llama-based models with billions of parameters, \n",
      "     enabling researchers and companies to fine-tune them for their own use cases.\n",
      "     The models are designed for a variety of tasks, including image classification, object detection, and semantic segmentation.\n",
      "     The open-sourcing of these models is a significant step towards making AI more accessible and useful for a wider range of users.\n"
     ]
    }
   ],
   "source": [
    "print('RAG Answer:\\n', answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f21e67a",
   "metadata": {},
   "source": [
    "Veamos algo interesante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "201e2a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Which company open-sourced Llama-based models and for what purpose?'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d56abbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_answer, answer = generate_answer(base_model, tokenizer, question, 256, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "36a846cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Answer (no RAG, no fine-tuning):\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(\"Baseline Answer (no RAG, no fine-tuning):\\n\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8ee27c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f527fa",
   "metadata": {},
   "source": [
    "Usemos de nuevo el prompt anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c486d2ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n    You are a helpful assistant specialized in technology news.\\n    Use ONLY the context below to answer the user question.\\n    If the answer is not in the context, say I don't know.\\n    Answer ONE short sentence. Do NOT repeat context or question\\n    \\n  Question: Which company open-sourced Llama-based models and for what purpose?\\n    \\n  Context: Meta open-sourced a set of Llama-based models with billions of parameters, \\n    enabling researchers and companies to fine-tune them for their own use cases.\\n    \\n Answer:\\n    \""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2f227fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Answer (no RAG, no fine-tuning):\n",
      " Meta open-sourced Llama-based models for research and development.\n",
      "     The models are designed for a wide range of applications, including natural language processing, image recognition, and more.\n",
      "     The open-sourcing of these models is a significant step towards making AI more accessible to a wider range of users.\n",
      "     Meta's Llama models are designed to be easy to use and can be fine-tuned for specific use cases.\n"
     ]
    }
   ],
   "source": [
    "raw_answer, answer = generate_answer(base_model, tokenizer, prompt, 256, 128)\n",
    "print(\"Baseline Answer (no RAG, no fine-tuning):\\n\", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a5d22b",
   "metadata": {},
   "source": [
    "Creamos un nuevo prompt que tenga ordenes, pregunta y espacio para respuesta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dbdf1ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "ONLY answer the question below. Do NOT repeat the question below in the answer.\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4881867a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Answer (no RAG, no fine-tuning):\n",
      " 1. Google\n",
      "2. Facebook\n",
      "3. Amazon\n",
      "4. Microsoft\n",
      "5. IBM\n",
      "\n",
      "6. IBM\n",
      "7. Google\n",
      "8. Amazon\n",
      "9. Microsoft\n",
      "10. Facebook\n",
      "\n",
      "11. IBM\n",
      "12. Google\n",
      "13. Amazon\n",
      "14. Facebook\n",
      "15. Microsoft\n",
      "\n",
      "16. IBM\n",
      "17. Google\n",
      "18. Amazon\n",
      "19. Microsoft\n",
      "20. Facebook\n",
      "\n",
      "21. IBM\n",
      "22. Google\n",
      "23. Amazon\n",
      "24. Microsoft\n",
      "25. Facebook\n",
      "\n",
      "26. IBM\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "raw_answer, answer = generate_answer(base_model, tokenizer, prompt, 256, 128)\n",
    "print(\"Baseline Answer (no RAG, no fine-tuning):\\n\", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67b5197",
   "metadata": {},
   "source": [
    "Veamos esto que también es interesante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "20e4b978",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"{question}:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e0bdbb02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Which company open-sourced Llama-based models and for what purpose?:'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9157fbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Answer (no RAG, no fine-tuning):\n",
      " Llama is a popular open-source modeling library for C++. It is a lightweight, efficient, and easy-to-use modeling library for C++. Llama is used in many applications, including game development, animation, and graphics.\n",
      "\n",
      "Llama is open-source and free to use. It is maintained by a community of developers and contributors. The community is actively working on improving the library and adding new features.\n",
      "\n",
      "Llama is used in many applications, including:\n",
      "\n",
      "1. Game development: Llama is used in many game development projects,\n"
     ]
    }
   ],
   "source": [
    "raw_answer, answer = generate_answer(base_model, tokenizer, prompt, 256, 128)\n",
    "print(\"Baseline Answer (no RAG, no fine-tuning):\\n\", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf294f9",
   "metadata": {},
   "source": [
    "Veamos ahora como hacer fine tuning con un toy example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "76bab45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Data/qa_data.json\", \"r\") as file:\n",
    "    qa_pairs = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dd1ad44f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'instruction': 'Which company released a new reasoning model optimized for tool use and RAG?',\n",
       "  'input': '',\n",
       "  'output': 'OpenAI released a new model optimized for tool use and retrieval-augmented generation.'},\n",
       " {'instruction': 'What did Google update to make it easier to deploy large language models?',\n",
       "  'input': '',\n",
       "  'output': 'Google updated its Vertex AI platform to make it easier to deploy and monitor large language models.'},\n",
       " {'instruction': 'Which company open-sourced Llama-based models and why is this important?',\n",
       "  'input': '',\n",
       "  'output': 'Meta open-sourced Llama-based models, enabling researchers and companies to fine-tune them for their own use cases.'},\n",
       " {'instruction': 'What AI features did Microsoft add to Office?',\n",
       "  'input': '',\n",
       "  'output': 'Microsoft added generative AI features to Office, including AI-powered summarization, drafting, and meeting notes.'},\n",
       " {'instruction': 'What did AWS introduce for inference workloads?',\n",
       "  'input': '',\n",
       "  'output': 'AWS introduced cheaper GPU instances optimized for inference workloads like chatbots, code assistants, and document question-answering.'},\n",
       " {'instruction': 'What did NVIDIA release to accelerate transformer inference?',\n",
       "  'input': '',\n",
       "  'output': 'NVIDIA released open-source libraries that accelerate transformer inference, improving performance on consumer GPUs.'},\n",
       " {'instruction': 'What research focus did Anthropic publish new work on?',\n",
       "  'input': '',\n",
       "  'output': 'Anthropic published research on improving constitutional AI with scalable oversight and safer model behavior.'},\n",
       " {'instruction': 'What AI capability is Apple reportedly testing for iPhones?',\n",
       "  'input': '',\n",
       "  'output': 'Apple is testing on-device LLMs that enable private offline capabilities like summarization and personal context reasoning.'},\n",
       " {'instruction': 'What did Hugging Face launch to improve model serving?',\n",
       "  'input': '',\n",
       "  'output': 'Hugging Face launched a new inference API tier with high throughput and native vLLM support.'},\n",
       " {'instruction': 'Which company released the Mixtral-8x22B model and what type of model is it?',\n",
       "  'input': '',\n",
       "  'output': 'Mistral AI released Mixtral-8x22B, a sparse mixture-of-experts model that provides state-of-the-art performance efficiently.'},\n",
       " {'instruction': 'What partnership did IBM announce involving geospatial data?',\n",
       "  'input': '',\n",
       "  'output': 'IBM partnered with NASA to fine-tune foundation models on geospatial data to improve climate and satellite analysis.'},\n",
       " {'instruction': 'What model did Databricks release and what is notable about it?',\n",
       "  'input': '',\n",
       "  'output': 'Databricks released DBRX, a 132B-parameter MoE model trained on curated scientific and enterprise datasets.'},\n",
       " {'instruction': 'What did Stability AI introduce with improved text-image alignment?',\n",
       "  'input': '',\n",
       "  'output': 'Stability AI introduced Stable Diffusion 3, offering better text-image alignment and reduced hallucinations.'},\n",
       " {'instruction': 'What new capability did Snowflake add for enterprise AI pipelines?',\n",
       "  'input': '',\n",
       "  'output': 'Snowflake added native vector search, enabling RAG workflows directly within its data warehouse.'},\n",
       " {'instruction': 'What product did Cohere launch for retrieval and semantic search?',\n",
       "  'input': '',\n",
       "  'output': 'Cohere launched an enterprise-grade embedding model designed for semantic search and multilingual retrieval.'},\n",
       " {'instruction': 'What AI enhancement did Red Hat introduce for DevOps workflows?',\n",
       "  'input': '',\n",
       "  'output': 'Red Hat introduced AI-enhanced DevOps tools, including automated deployment validation powered by small LLMs.'},\n",
       " {'instruction': 'What updates did Salesforce make to Einstein GPT?',\n",
       "  'input': '',\n",
       "  'output': 'Salesforce updated Einstein GPT with improved CRM reasoning, including lead scoring and automated email drafting.'},\n",
       " {'instruction': 'What AI feature did Dropbox add to help users navigate their files?',\n",
       "  'input': '',\n",
       "  'output': 'Dropbox added AI-powered universal search that allows semantic querying across documents, PDFs, and images.'},\n",
       " {'instruction': 'How is Slack using AI to help teams stay informed?',\n",
       "  'input': '',\n",
       "  'output': 'Slack added AI summarization for channels and threads, generating digests and extracting key decisions.'},\n",
       " {'instruction': 'What real-time AI capabilities did Zoom add to its platform?',\n",
       "  'input': '',\n",
       "  'output': 'Zoom added real-time translation and AI-generated meeting action items powered by a multilingual transformer model.'}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5b7b20ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output'],\n",
       "    num_rows: 20\n",
       "})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.from_list(qa_pairs)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f55f90f",
   "metadata": {},
   "source": [
    "### Supervised FT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5881e364",
   "metadata": {},
   "source": [
    "![ft1](./Images/FT1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f824a1cf",
   "metadata": {},
   "source": [
    "![ft2](./Images/FT2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc6d30e",
   "metadata": {},
   "source": [
    "![ft3](./Images/FT3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae264760",
   "metadata": {},
   "source": [
    "Fuente: P. Iusztin & M. Labonne - LLM Engineer's Handbook - Chapter 5 - Supervised Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aca8cb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_example(example):\n",
    "    # Alpaca-style formatting\n",
    "    if example[\"input\"]:\n",
    "        return f\"\"\"Below is an instruction and an input. Write a helpful answer.\n",
    "\n",
    "### Instruction:\n",
    "{example[\"instruction\"]}\n",
    "\n",
    "### Input:\n",
    "{example[\"input\"]}\n",
    "\n",
    "### Response:\n",
    "{example[\"output\"]}\n",
    "\"\"\"\n",
    "    else:\n",
    "        return f\"\"\"Below is an instruction. Write a helpful answer.\n",
    "\n",
    "### Instruction:\n",
    "{example[\"instruction\"]}\n",
    "\n",
    "### Response:\n",
    "{example[\"output\"]}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def tokenize_function(example):\n",
    "    text = format_example(example)\n",
    "    tokenized = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        max_length=256,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    # For causal LM, labels = input_ids\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "db21f402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29ce96986b204ed68f74fe2b76016042",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(tokenize_function, batched=False)\n",
    "\n",
    "# Remove the original text columns\n",
    "tokenized_dataset = tokenized_dataset.remove_columns([\"instruction\", \"input\", \"output\"])\n",
    "\n",
    "# Set format\n",
    "tokenized_dataset.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1e04c01e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([    1, 13866,   338,   385, 15278, 29889, 14350,   263,  8444,  1234,\n",
       "         29889,    13,    13,  2277, 29937,  2799,  4080, 29901,    13,  8809,\n",
       "           436,  5001,  5492,   263,   716, 24481,  1904, 27545,   363,  5780,\n",
       "           671,   322,   390, 10051, 29973,    13,    13,  2277, 29937, 13291,\n",
       "         29901,    13,  6585, 23869,  5492,   263,   716,  1904, 27545,   363,\n",
       "          5780,   671,   322,  5663, 16837, 29899,  2987,   358,   287, 12623,\n",
       "         29889,    13,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'labels': tensor([    1, 13866,   338,   385, 15278, 29889, 14350,   263,  8444,  1234,\n",
       "         29889,    13,    13,  2277, 29937,  2799,  4080, 29901,    13,  8809,\n",
       "           436,  5001,  5492,   263,   716, 24481,  1904, 27545,   363,  5780,\n",
       "           671,   322,   390, 10051, 29973,    13,    13,  2277, 29937, 13291,\n",
       "         29901,    13,  6585, 23869,  5492,   263,   716,  1904, 27545,   363,\n",
       "          5780,   671,   322,  5663, 16837, 29899,  2987,   358,   287, 12623,\n",
       "         29889,    13,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2])}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "84f24d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    tokenized_dataset,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3267f3",
   "metadata": {},
   "source": [
    "Definimos un nuevo modelo a realizar FT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7e025bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name, quantization_config=bnb_config, device_map=\"auto\", use_cache=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3cb673ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"v_proj\",\n",
    "        \"k_proj\",\n",
    "        \"o_proj\",\n",
    "    ],  # may need to adjust per model\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d26d1b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 2,252,800 || all params: 1,102,301,184 || trainable%: 0.2044\n"
     ]
    }
   ],
   "source": [
    "# Prepare model for k-bit training (LoRA on top of 4-bit base)\n",
    "ft_model.to(device).train()\n",
    "ft_model = prepare_model_for_kbit_training(ft_model)\n",
    "ft_model = get_peft_model(ft_model, lora_config)\n",
    "ft_model.gradient_checkpointing_enable(\n",
    "    gradient_checkpointing_kwargs={\"use_reentrant\": False}\n",
    ")\n",
    "ft_model.enable_input_require_grads()\n",
    "ft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ce2a0727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                                            Param #\n",
       "==========================================================================================\n",
       "PeftModelForCausalLM                                              --\n",
       "├─LoraModel: 1-1                                                  --\n",
       "│    └─LlamaForCausalLM: 2-1                                      --\n",
       "│    │    └─LlamaModel: 3-1                                       552,323,072\n",
       "│    │    └─Linear: 3-2                                           (65,536,000)\n",
       "==========================================================================================\n",
       "Total params: 617,859,072\n",
       "Trainable params: 2,252,800\n",
       "Non-trainable params: 615,606,272\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(ft_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f35a6e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(ft_model.parameters(), lr=1e-3, amsgrad=True, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2a1ae04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Step 1 | Loss: 14.7732\n",
      "Epoch 1 | Step 2 | Loss: 8.4062\n",
      "Epoch 1 | Step 3 | Loss: 3.3998\n",
      "Epoch 1 | Step 4 | Loss: 1.1976\n",
      "Epoch 1 | Step 5 | Loss: 0.9066\n",
      "Epoch 1 | Step 6 | Loss: 0.9513\n",
      "Epoch 1 | Step 7 | Loss: 0.9903\n",
      "Epoch 1 | Step 8 | Loss: 0.9632\n",
      "Epoch 1 | Step 9 | Loss: 0.8716\n",
      "Epoch 1 | Step 10 | Loss: 0.8545\n",
      "== Epoch 1 finished | Avg loss: 3.3314 ==\n",
      "Epoch 2 | Step 1 | Loss: 0.7006\n",
      "Epoch 2 | Step 2 | Loss: 0.6870\n",
      "Epoch 2 | Step 3 | Loss: 0.6462\n",
      "Epoch 2 | Step 4 | Loss: 0.7764\n",
      "Epoch 2 | Step 5 | Loss: 0.6426\n",
      "Epoch 2 | Step 6 | Loss: 0.6502\n",
      "Epoch 2 | Step 7 | Loss: 0.5551\n",
      "Epoch 2 | Step 8 | Loss: 0.4871\n",
      "Epoch 2 | Step 9 | Loss: 0.5176\n",
      "Epoch 2 | Step 10 | Loss: 0.5034\n",
      "== Epoch 2 finished | Avg loss: 0.6166 ==\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        # batch is a dict of tensors with shape [batch_size, seq_len]\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = ft_model(**batch)\n",
    "\n",
    "        loss = outputs.loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1} | Step {step+1} | Loss: {loss.item():.4f}\")\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"== Epoch {epoch+1} finished | Avg loss: {avg_loss:.4f} ==\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1589ab",
   "metadata": {},
   "source": [
    "Vamos a cargar el modelo ya entrenado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7c96534b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved LoRA adapter to: ./tinyllama-tech-lora\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"./tinyllama-tech-lora\"\n",
    "ft_model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "print(\"Saved LoRA adapter to:\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2e342407",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "13df8c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load FT Model\n",
    "# ft_model = AutoModelForCausalLM.from_pretrained(output_dir)\n",
    "\n",
    "# # Load the tokenizer\n",
    "# tokenizer = AutoTokenizer.from_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9d1f839d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ft_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d3eae8",
   "metadata": {},
   "source": [
    "Nuevamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c54ea131",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Which company open-sourced Llama-based models and for what purpose?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9f42163e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
      "Caching is incompatible with gradient checkpointing in LlamaDecoderLayer. Setting `past_key_values=None`.\n"
     ]
    }
   ],
   "source": [
    "raw_answer, answer = generate_answer(ft_model, tokenizer, question, 256, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ada362d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d21572fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Which company open-sourced Llama-based models and for what purpose?:'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9231c44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_answer, answer = generate_answer(ft_model, tokenizer, prompt, 256, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4a6b41a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b9a66f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- RAG (no FT) ---\n",
      "Meta has open-sourced a set of Llama-based models with billions of parameters, \n",
      "     enabling researchers and companies to fine-tune them for their own use cases.\n",
      "     The models are open-sourced under the Apache 2.0 license.\n",
      "     The models are available for use in research and development projects, \n",
      "     and can be used for various applications such as natural language processing, \n",
      "     computer vision, and speech recognition.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- RAG (no FT) ---\")\n",
    "prompt, full_output, gen_output, contexts, token_count = rag_answer(\n",
    "    base_model, tokenizer, question, 3, 256, 128, 'faiss'\n",
    ")\n",
    "print(gen_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5ab86353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Which company open-sourced Llama-based models and for what purpose?'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "79fbd5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fine-tuned + RAG ---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Fine-tuned + RAG ---\")\n",
    "_, raw_answer, answer, _, _ = rag_answer(\n",
    "    ft_model, tokenizer, question, 3, 256, 128, \"faiss\"\n",
    ")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcef0e63",
   "metadata": {},
   "source": [
    "Ahora, vamos a entrenar un modelo un poco más grande desde HF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5049b610",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_ds = load_dataset(\"HuggingFaceH4/ultrafeedback_binarized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "22982131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['prompt', 'prompt_id', 'chosen', 'rejected', 'messages', 'score_chosen', 'score_rejected'],\n",
      "    num_rows: 61135\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "train_sft = raw_ds[\"train_sft\"]\n",
    "test_sft = raw_ds[\"test_sft\"]\n",
    "pprint(train_sft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8da39beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chosen': [{'content': 'how can i develop a habit of drawing daily',\n",
      "             'role': 'user'},\n",
      "            {'content': 'Developing a daily habit of drawing can be '\n",
      "                        'challenging but with consistent practice and a few '\n",
      "                        'tips, it can become an enjoyable and rewarding part '\n",
      "                        'of your daily routine. Here are some strategies to '\n",
      "                        'help you develop the habit of drawing daily:\\n'\n",
      "                        '\\n'\n",
      "                        '1. Set a specific time: Allocate a specific time of '\n",
      "                        'the day to draw. It could be in the morning, '\n",
      "                        'afternoon, or evening. Make drawing a part of your '\n",
      "                        'daily routine.\\n'\n",
      "                        '2. Set a specific duration: Determine the amount of '\n",
      "                        'time you want to spend on drawing each day. It can be '\n",
      "                        'as little as 10 minutes or as long as an hour. Be '\n",
      "                        'consistent with the duration to help build the '\n",
      "                        'habit.\\n'\n",
      "                        \"3. Start small and simple: Don't try to create a \"\n",
      "                        'masterpiece every day, start with simple and '\n",
      "                        'easy-to-do sketches. Focus on improving your skills '\n",
      "                        'gradually.\\n'\n",
      "                        '4. Use a variety of tools and mediums: Experiment '\n",
      "                        'with different tools like pencils, pens, markers, and '\n",
      "                        'different mediums like paper, canvas, or digital apps '\n",
      "                        'to keep your drawing practice interesting and '\n",
      "                        'engaging.\\n'\n",
      "                        '5. Take breaks and rest: Taking breaks and resting '\n",
      "                        'after some time of drawing can help you avoid burnout '\n",
      "                        'and stay motivated.\\n'\n",
      "                        '6. Challenge yourself: Set challenges like drawing '\n",
      "                        'objects from memory or a specific subject to improve '\n",
      "                        'your skills and keep your drawing practice '\n",
      "                        'interesting.\\n'\n",
      "                        '7. Track your progress: Keep a record of your daily '\n",
      "                        'drawing practice and track your progress. This can be '\n",
      "                        'a source of motivation and help you see how far '\n",
      "                        \"you've come.\\n\"\n",
      "                        '\\n'\n",
      "                        'Remember, developing a habit takes time and patience. '\n",
      "                        'Stay consistent with your drawing practice, be '\n",
      "                        'flexible and open to trying new things, and with '\n",
      "                        \"time, you'll develop a habit of daily drawing that \"\n",
      "                        'brings you joy and satisfaction.',\n",
      "             'role': 'assistant'}],\n",
      " 'messages': [{'content': 'how can i develop a habit of drawing daily',\n",
      "               'role': 'user'},\n",
      "              {'content': 'Developing a daily habit of drawing can be '\n",
      "                          'challenging but with consistent practice and a few '\n",
      "                          'tips, it can become an enjoyable and rewarding part '\n",
      "                          'of your daily routine. Here are some strategies to '\n",
      "                          'help you develop the habit of drawing daily:\\n'\n",
      "                          '\\n'\n",
      "                          '1. Set a specific time: Allocate a specific time of '\n",
      "                          'the day to draw. It could be in the morning, '\n",
      "                          'afternoon, or evening. Make drawing a part of your '\n",
      "                          'daily routine.\\n'\n",
      "                          '2. Set a specific duration: Determine the amount of '\n",
      "                          'time you want to spend on drawing each day. It can '\n",
      "                          'be as little as 10 minutes or as long as an hour. '\n",
      "                          'Be consistent with the duration to help build the '\n",
      "                          'habit.\\n'\n",
      "                          \"3. Start small and simple: Don't try to create a \"\n",
      "                          'masterpiece every day, start with simple and '\n",
      "                          'easy-to-do sketches. Focus on improving your skills '\n",
      "                          'gradually.\\n'\n",
      "                          '4. Use a variety of tools and mediums: Experiment '\n",
      "                          'with different tools like pencils, pens, markers, '\n",
      "                          'and different mediums like paper, canvas, or '\n",
      "                          'digital apps to keep your drawing practice '\n",
      "                          'interesting and engaging.\\n'\n",
      "                          '5. Take breaks and rest: Taking breaks and resting '\n",
      "                          'after some time of drawing can help you avoid '\n",
      "                          'burnout and stay motivated.\\n'\n",
      "                          '6. Challenge yourself: Set challenges like drawing '\n",
      "                          'objects from memory or a specific subject to '\n",
      "                          'improve your skills and keep your drawing practice '\n",
      "                          'interesting.\\n'\n",
      "                          '7. Track your progress: Keep a record of your daily '\n",
      "                          'drawing practice and track your progress. This can '\n",
      "                          'be a source of motivation and help you see how far '\n",
      "                          \"you've come.\\n\"\n",
      "                          '\\n'\n",
      "                          'Remember, developing a habit takes time and '\n",
      "                          'patience. Stay consistent with your drawing '\n",
      "                          'practice, be flexible and open to trying new '\n",
      "                          \"things, and with time, you'll develop a habit of \"\n",
      "                          'daily drawing that brings you joy and satisfaction.',\n",
      "               'role': 'assistant'}],\n",
      " 'prompt': 'how can i develop a habit of drawing daily',\n",
      " 'prompt_id': '086b3e24f29b8956a01059f79c56db35d118a06fb6b844b095737d042795cd43',\n",
      " 'rejected': [{'content': 'how can i develop a habit of drawing daily',\n",
      "               'role': 'user'},\n",
      "              {'content': 'As an AI language model, I cannot personally '\n",
      "                          'develop habits for you. But, here are some tips for '\n",
      "                          'developing a habit of drawing daily:\\n'\n",
      "                          '\\n'\n",
      "                          '1. Start small: Start with simple drawings or '\n",
      "                          'doodles and gradually increase the complexity of '\n",
      "                          'your drawings.\\n'\n",
      "                          '\\n'\n",
      "                          '2. Set a schedule: Set a specific time every day to '\n",
      "                          'draw, and try to stick to it as much as possible.\\n'\n",
      "                          '\\n'\n",
      "                          \"3. Make it fun: Don't pressure yourself to create \"\n",
      "                          'masterpieces every time you draw. Make it a '\n",
      "                          'relaxing and enjoyable experience.\\n'\n",
      "                          '\\n'\n",
      "                          '4. Use resources: There are many drawing tutorials '\n",
      "                          'available online. Use resources like YouTube or '\n",
      "                          'online drawing courses to help you improve your '\n",
      "                          'skills.\\n'\n",
      "                          '\\n'\n",
      "                          '5. Surround yourself with inspiration: Expose '\n",
      "                          'yourself to a variety of art forms, such as '\n",
      "                          'paintings, illustrations, and photographs, to '\n",
      "                          'inspire and motivate you.\\n'\n",
      "                          '\\n'\n",
      "                          'Remember, everyone has their own creative style and '\n",
      "                          'pace. Just keep practicing and enjoying the process '\n",
      "                          'of drawing.',\n",
      "               'role': 'assistant'}],\n",
      " 'score_chosen': 8.5,\n",
      " 'score_rejected': 8.5}\n"
     ]
    }
   ],
   "source": [
    "pprint(train_sft[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4c9c332e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ultrafeedback_to_qa(example):\n",
    "    \"\"\"\n",
    "    Convert one UltraFeedback example into your {instruction, input, output} format.\n",
    "    We'll use the 'messages' field.\n",
    "    \"\"\"\n",
    "    msgs = example[\"messages\"]\n",
    "\n",
    "    # last user message\n",
    "    user_msgs = [m[\"content\"] for m in msgs if m[\"role\"] == \"user\"]\n",
    "    # last assistant message\n",
    "    assistant_msgs = [m[\"content\"] for m in msgs if m[\"role\"] == \"assistant\"]\n",
    "\n",
    "    if not user_msgs or not assistant_msgs:\n",
    "        return {\n",
    "            \"instruction\": \"\",\n",
    "            \"input\": \"\",\n",
    "            \"output\": \"\",\n",
    "        }\n",
    "\n",
    "    instruction = user_msgs[-1].strip()\n",
    "    output = assistant_msgs[-1].strip()\n",
    "\n",
    "    return {\n",
    "        \"instruction\": instruction,\n",
    "        \"input\": \"\",\n",
    "        \"output\": output,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b9af61cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For GPU sanity, start with a subset\n",
    "train_small = train_sft.shuffle().select(range(1000))\n",
    "eval_small = test_sft.shuffle().select(range(100))\n",
    "\n",
    "train_qa = [ultrafeedback_to_qa(ex) for ex in train_small]\n",
    "eval_qa = [ultrafeedback_to_qa(ex) for ex in eval_small]\n",
    "\n",
    "# Filter out empties\n",
    "train_qa = [ex for ex in train_qa if ex[\"instruction\"] and ex[\"output\"]]\n",
    "eval_qa = [ex for ex in eval_qa if ex[\"instruction\"] and ex[\"output\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4535d12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': '',\n",
      " 'instruction': 'Given a set of instructions written in German and a table of '\n",
      "                'necessary components with their corresponding product codes, '\n",
      "                'come up with a list of supplies needed to complete the '\n",
      "                'instructions and build a model car. The model car should have '\n",
      "                'a specific color scheme, and the components must be sourced '\n",
      "                'from a specific supplier within a given budget. Additionally, '\n",
      "                'the instructions require the use of specific tools that may '\n",
      "                'not be readily available, such as a mini lathe and a laser '\n",
      "                'cutter, which must also be included in the list of supplies. '\n",
      "                'The model car should also have specific dimensions and must '\n",
      "                'be able to withstand a certain amount of weight without '\n",
      "                'breaking. Finally, the list of supplies should include a '\n",
      "                'detailed cost breakdown and an estimated time required for '\n",
      "                'the completion of the project, including any necessary '\n",
      "                'research or sourcing of materials.',\n",
      " 'output': 'To assist you with this task, I would first like to clarify that '\n",
      "           'the instructions are written in German, and therefore, I will need '\n",
      "           'to translate them into a language that I can understand and '\n",
      "           'process. Additionally, I will need to source the necessary '\n",
      "           'components and tools from a specific supplier within a given '\n",
      "           'budget, while ensuring that the model car meets the required '\n",
      "           'specifications, including a specific color scheme, dimensions, and '\n",
      "           'weight capacity.\\n'\n",
      "           '\\n'\n",
      "           'To start, I would recommend the following components:\\n'\n",
      "           '\\n'\n",
      "           '* Body and chassis: Aluminum frame with carbon fiber panels '\n",
      "           '(Product Code: CAR-001)\\n'\n",
      "           '* Wheels: High-performance rubber tires with aluminum rims '\n",
      "           '(Product Code: WHE-002)\\n'\n",
      "           '* Suspension: Adjustable coil-over suspension (Product Code: '\n",
      "           'SUS-003)\\n'\n",
      "           '* Engine: High-performance electric motor (Product Code: ENG-004)\\n'\n",
      "           '* Battery: Rechargeable lithium-ion battery (Product Code: '\n",
      "           'BAT-005)\\n'\n",
      "           '* Steering: Remote-controlled servo motor (Product Code: SER-006)\\n'\n",
      "           '* Brake system: Disc brakes with hydraulic system (Product Code: '\n",
      "           'BRK-007)\\n'\n",
      "           '\\n'\n",
      "           'Tools:\\n'\n",
      "           '\\n'\n",
      "           '* Mini lathe (Product Code: TOOL-008)\\n'\n",
      "           '* Laser cutter (Product Code: TOOL-009)\\n'\n",
      "           '\\n'\n",
      "           'The estimated cost for the above components and tools would be:\\n'\n",
      "           '\\n'\n",
      "           '* Component Cost: €500\\n'\n",
      "           '* Tool Cost: €300\\n'\n",
      "           '* Total Cost: €800\\n'\n",
      "           '\\n'\n",
      "           'The estimated time required to complete the project, including '\n",
      "           'research and sourcing materials, would be approximately 20 hours.\\n'\n",
      "           '\\n'\n",
      "           'Before proceeding with the build, I would like to ensure that the '\n",
      "           'instructions are clear and accurate. I would recommend translating '\n",
      "           'the instructions into a language that I can understand and '\n",
      "           'process, and then breaking down the instructions into individual '\n",
      "           'steps to ensure that all necessary components and tools are '\n",
      "           'accounted for.\\n'\n",
      "           '\\n'\n",
      "           'Once the components and tools are sourced, I would recommend '\n",
      "           'beginning the build by assembling the chassis and body, followed '\n",
      "           'by the suspension, engine, battery, steering, and brake system. I '\n",
      "           'would then suggest painting the model car in the desired color '\n",
      "           'scheme and adding any additional details or decals.\\n'\n",
      "           '\\n'\n",
      "           'Finally, I would recommend testing the model car to ensure that it '\n",
      "           'meets the required specifications, including weight capacity and '\n",
      "           'dimensions.\\n'\n",
      "           '\\n'\n",
      "           'I hope this information is helpful in getting started with your '\n",
      "           'project. Please let me know if you have any further questions or '\n",
      "           'concerns.'}\n"
     ]
    }
   ],
   "source": [
    "pprint(train_qa[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1f052e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_list(train_qa)\n",
    "eval_dataset = Dataset.from_list(eval_qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0ffd41f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': '',\n",
      " 'instruction': 'Given a set of instructions written in German and a table of '\n",
      "                'necessary components with their corresponding product codes, '\n",
      "                'come up with a list of supplies needed to complete the '\n",
      "                'instructions and build a model car. The model car should have '\n",
      "                'a specific color scheme, and the components must be sourced '\n",
      "                'from a specific supplier within a given budget. Additionally, '\n",
      "                'the instructions require the use of specific tools that may '\n",
      "                'not be readily available, such as a mini lathe and a laser '\n",
      "                'cutter, which must also be included in the list of supplies. '\n",
      "                'The model car should also have specific dimensions and must '\n",
      "                'be able to withstand a certain amount of weight without '\n",
      "                'breaking. Finally, the list of supplies should include a '\n",
      "                'detailed cost breakdown and an estimated time required for '\n",
      "                'the completion of the project, including any necessary '\n",
      "                'research or sourcing of materials.',\n",
      " 'output': 'To assist you with this task, I would first like to clarify that '\n",
      "           'the instructions are written in German, and therefore, I will need '\n",
      "           'to translate them into a language that I can understand and '\n",
      "           'process. Additionally, I will need to source the necessary '\n",
      "           'components and tools from a specific supplier within a given '\n",
      "           'budget, while ensuring that the model car meets the required '\n",
      "           'specifications, including a specific color scheme, dimensions, and '\n",
      "           'weight capacity.\\n'\n",
      "           '\\n'\n",
      "           'To start, I would recommend the following components:\\n'\n",
      "           '\\n'\n",
      "           '* Body and chassis: Aluminum frame with carbon fiber panels '\n",
      "           '(Product Code: CAR-001)\\n'\n",
      "           '* Wheels: High-performance rubber tires with aluminum rims '\n",
      "           '(Product Code: WHE-002)\\n'\n",
      "           '* Suspension: Adjustable coil-over suspension (Product Code: '\n",
      "           'SUS-003)\\n'\n",
      "           '* Engine: High-performance electric motor (Product Code: ENG-004)\\n'\n",
      "           '* Battery: Rechargeable lithium-ion battery (Product Code: '\n",
      "           'BAT-005)\\n'\n",
      "           '* Steering: Remote-controlled servo motor (Product Code: SER-006)\\n'\n",
      "           '* Brake system: Disc brakes with hydraulic system (Product Code: '\n",
      "           'BRK-007)\\n'\n",
      "           '\\n'\n",
      "           'Tools:\\n'\n",
      "           '\\n'\n",
      "           '* Mini lathe (Product Code: TOOL-008)\\n'\n",
      "           '* Laser cutter (Product Code: TOOL-009)\\n'\n",
      "           '\\n'\n",
      "           'The estimated cost for the above components and tools would be:\\n'\n",
      "           '\\n'\n",
      "           '* Component Cost: €500\\n'\n",
      "           '* Tool Cost: €300\\n'\n",
      "           '* Total Cost: €800\\n'\n",
      "           '\\n'\n",
      "           'The estimated time required to complete the project, including '\n",
      "           'research and sourcing materials, would be approximately 20 hours.\\n'\n",
      "           '\\n'\n",
      "           'Before proceeding with the build, I would like to ensure that the '\n",
      "           'instructions are clear and accurate. I would recommend translating '\n",
      "           'the instructions into a language that I can understand and '\n",
      "           'process, and then breaking down the instructions into individual '\n",
      "           'steps to ensure that all necessary components and tools are '\n",
      "           'accounted for.\\n'\n",
      "           '\\n'\n",
      "           'Once the components and tools are sourced, I would recommend '\n",
      "           'beginning the build by assembling the chassis and body, followed '\n",
      "           'by the suspension, engine, battery, steering, and brake system. I '\n",
      "           'would then suggest painting the model car in the desired color '\n",
      "           'scheme and adding any additional details or decals.\\n'\n",
      "           '\\n'\n",
      "           'Finally, I would recommend testing the model car to ensure that it '\n",
      "           'meets the required specifications, including weight capacity and '\n",
      "           'dimensions.\\n'\n",
      "           '\\n'\n",
      "           'I hope this information is helpful in getting started with your '\n",
      "           'project. Please let me know if you have any further questions or '\n",
      "           'concerns.'}\n"
     ]
    }
   ],
   "source": [
    "pprint(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2f7b7148",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_ex(example):\n",
    "    instr = example[\"instruction\"]\n",
    "    inp = example[\"input\"]\n",
    "    out = example[\"output\"]\n",
    "\n",
    "    if inp:\n",
    "        prompt = (\n",
    "            \"Below is an instruction and additional input. \"\n",
    "            \"Write a helpful, honest, and concise response.\\n\\n\"\n",
    "            f\"### Instruction:\\n{instr}\\n\\n\"\n",
    "            f\"### Input:\\n{inp}\\n\\n\"\n",
    "            \"### Response:\\n\"\n",
    "        )\n",
    "    else:\n",
    "        prompt = (\n",
    "            \"Below is an instruction. \"\n",
    "            \"Write a helpful, honest, and concise response.\\n\\n\"\n",
    "            f\"### Instruction:\\n{instr}\\n\\n\"\n",
    "            \"### Response:\\n\"\n",
    "        )\n",
    "\n",
    "    # For causal LM, we feed prompt + output as a single sequence\n",
    "    full_text = prompt + out\n",
    "    return {\"text\": full_text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "042640fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf66fd70154843379a4514f7ca4f8f5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0706d193e5ac4735aefa3189126ca90f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(format_ex)\n",
    "eval_dataset = eval_dataset.map(format_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b9438257",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_fn(example):\n",
    "    return tokenizer(\n",
    "        example[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=256,\n",
    "        padding=\"max_length\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "84b7f0c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc913b8d4f8c4ef58b8ee13e14133a21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a33b680d66c4792b508ae4d57e2ec1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_tokenized = train_dataset.map(\n",
    "    tokenize_fn, batched=True, remove_columns=train_dataset.column_names\n",
    ")\n",
    "eval_tokenized = eval_dataset.map(\n",
    "    tokenize_fn, batched=True, remove_columns=eval_dataset.column_names\n",
    ")\n",
    "\n",
    "train_tokenized.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
    "eval_tokenized.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "02162e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "033c0b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 4,505,600 || all params: 1,104,553,984 || trainable%: 0.4079\n"
     ]
    }
   ],
   "source": [
    "ft_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    use_cache=False,\n",
    ")\n",
    "\n",
    "ft_model = prepare_model_for_kbit_training(ft_model)\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"],  # typical for Llama-like\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "ft_model = get_peft_model(ft_model, lora_config)\n",
    "ft_model.gradient_checkpointing_enable(\n",
    "    gradient_checkpointing_kwargs={\"use_reentrant\": False}\n",
    ")\n",
    "ft_model.enable_input_require_grads()\n",
    "ft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6f207a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"./tinyllama-ultrafeedback-lora\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bf1f84c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=8,  # effective batch size = 8\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=1,  # start with 1 epoch; increase if stable\n",
    "    warmup_ratio=0.03,\n",
    "    logging_steps=20,\n",
    "    eval_steps=200,\n",
    "    save_steps=200,\n",
    "    save_total_limit=2,\n",
    "    report_to=[],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "986e5685",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=ft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=eval_tokenized,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7969619c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  7/125 04:26 < 1:44:38, 0.02 it/s, Epoch 0.05/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5195fd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter_dir = \"./tinyllama-ultrafeedback-lora-adapter\"\n",
    "ft_model.save_pretrained(adapter_dir)\n",
    "tokenizer.save_pretrained(adapter_dir)\n",
    "print(\"Saved LoRA adapter to:\", adapter_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbbffb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_docs = [\n",
    "    f\"User: {ex['prompt']}\\n\\nAssistant: {ultrafeedback_to_qa(ex)['output']}\"\n",
    "    for ex in train_small\n",
    "]\n",
    "\n",
    "corpus_titles = [f\"UltraFeedback sample {i}\" for i in range(len(corpus_docs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b26442d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute embeddings\n",
    "doc_embeddings = embedder.encode(\n",
    "    corpus_docs,\n",
    "    convert_to_numpy=True,\n",
    "    show_progress_bar=True,\n",
    "    device=device,\n",
    "    normalize_embeddings=True,\n",
    ")\n",
    "doc_embeddings = np.array(doc_embeddings).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0144f651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn\n",
    "nn_index = NearestNeighbors(n_neighbors=10, metric=\"cosine\")\n",
    "nn_index.fit(doc_embeddings)\n",
    "# Faiss\n",
    "faiss_emb = np.array(doc_embeddings).astype(\"float32\")\n",
    "faiss_index = faiss.IndexFlatIP(\n",
    "    faiss_emb.shape[1]\n",
    ")  # cosine similarity via inner product\n",
    "faiss.normalize_L2(faiss_emb)\n",
    "faiss_index.add(faiss_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c13e50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"how can i develop a habit of drawing daily\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0b30ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_answer, answer = generate_answer(ft_model, tokenizer, question, tokenizer.max_length, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824c33da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4067b9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bd310d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_answer, answer = generate_answer(ft_model, tokenizer, prompt, 256, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b628a95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c2cb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- RAG (no FT) ---\")\n",
    "prompt, full_output, gen_output, contexts, token_count = rag_answer(\n",
    "    base_model, tokenizer, question, 3, 256, 128, 'faiss'\n",
    ")\n",
    "print(gen_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd3f2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaebba1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Fine-tuned + RAG ---\")\n",
    "_, raw_answer, answer, _, _ = rag_answer(\n",
    "    ft_model, tokenizer, question, 3, 256, 128, \"faiss\"\n",
    ")\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
